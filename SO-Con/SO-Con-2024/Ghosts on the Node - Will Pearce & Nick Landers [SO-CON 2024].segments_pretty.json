{
  "segments": [
    {
      "Time_Start": 0.0,
      "Time_End": 8.84,
      "Text": "This text was transcribed using whisper model: large-v2\n\n Hi, so I'm Will Pierce, and then this is co-founder Nick Landers."
    },
    {
      "Time_Start": 8.84,
      "Time_End": 13.8,
      "Text": " We've been in the security community for quite some time, and then I disappeared and did"
    },
    {
      "Time_Start": 13.8,
      "Time_End": 17.72,
      "Text": " machine learning for a little bit, and maybe now I'm back."
    },
    {
      "Time_Start": 17.72,
      "Time_End": 21.8,
      "Text": " But effectively, we kind of started this company called Dreadnought."
    },
    {
      "Time_Start": 21.8,
      "Time_End": 24.68,
      "Text": " We do like offensive machine learning stuff."
    },
    {
      "Time_Start": 24.68,
      "Time_End": 33.24,
      "Text": " My background is I was an operator at Silent Brick Security, and then I went on to help"
    },
    {
      "Time_Start": 33.24,
      "Time_End": 38.28,
      "Text": " start the AI Red team at Microsoft, and then NVIDIA, and then I'm now here."
    },
    {
      "Time_Start": 38.28,
      "Time_End": 41.64,
      "Text": " Yeah, Nick Landers, similar background."
    },
    {
      "Time_Start": 41.64,
      "Time_End": 44.92,
      "Text": " Mine's a little bit more on the malware development engineering side."
    },
    {
      "Time_Start": 44.92,
      "Time_End": 50.08,
      "Text": " Worked at Silent Brick for many years, and Will and I broke off, stayed friends, and"
    },
    {
      "Time_Start": 50.08,
      "Time_End": 52.36,
      "Text": " just came back together last year to do this thing."
    },
    {
      "Time_Start": 53.24,
      "Time_End": 54.24,
      "Text": " Really excited."
    },
    {
      "Time_Start": 54.24,
      "Time_End": 56.76,
      "Text": " Yeah, I have a ton of cool stuff to share, so."
    },
    {
      "Time_Start": 56.76,
      "Time_End": 60.84,
      "Text": " Next, we have three primary things."
    },
    {
      "Time_Start": 60.84,
      "Time_End": 65.8,
      "Text": " We do capture the flag, so if you played the Kaggle competition for the AI CTF that we"
    },
    {
      "Time_Start": 65.8,
      "Time_End": 72.72,
      "Text": " do through AI Village at DEF CON, we do cyber evaluations."
    },
    {
      "Time_Start": 72.72,
      "Time_End": 78.8,
      "Text": " We effectively help them figure out how safe or unsafe their models are, I suppose."
    },
    {
      "Time_Start": 78.8,
      "Time_End": 83.2,
      "Text": " And then we do some AI Red team tooling, which is kind of algorithmic attacks against"
    },
    {
      "Time_Start": 83.2,
      "Time_End": 84.2,
      "Text": " models."
    },
    {
      "Time_Start": 84.2,
      "Time_End": 86.08,
      "Text": " And just quick history."
    },
    {
      "Time_Start": 86.08,
      "Time_End": 92.32,
      "Text": " So our first little foray into the space was sort of detecting sandboxes with neural networks"
    },
    {
      "Time_Start": 92.32,
      "Time_End": 93.56,
      "Text": " and decision trees."
    },
    {
      "Time_Start": 93.56,
      "Time_End": 96.64,
      "Text": " And if you go back and look at that research, it's pretty terrible."
    },
    {
      "Time_Start": 96.64,
      "Time_End": 98.52,
      "Text": " I mean, it's not terrible."
    },
    {
      "Time_Start": 98.52,
      "Time_End": 100.2,
      "Text": " The code's terrible."
    },
    {
      "Time_Start": 100.2,
      "Time_End": 102.56,
      "Text": " And the setup is kind of terrible."
    },
    {
      "Time_Start": 102.56,
      "Time_End": 107.28,
      "Text": " And I think that's just a function of us not being coming from an academic space and coming"
    },
    {
      "Time_Start": 107.28,
      "Time_End": 109.64,
      "Text": " from a more operational space."
    },
    {
      "Time_Start": 109.64,
      "Time_End": 114.36,
      "Text": " But the fact of the matter is it kind of worked."
    },
    {
      "Time_Start": 114.36,
      "Time_End": 119.2,
      "Text": " And then we went on to do a bunch of different research and build a bunch of tools."
    },
    {
      "Time_Start": 119.2,
      "Time_End": 124.08,
      "Text": " So proof-putting, this is actually our first talk together since proof-putting, which is"
    },
    {
      "Time_Start": 124.08,
      "Time_End": 125.08,
      "Text": " in DerbyCon."
    },
    {
      "Time_Start": 125.08,
      "Time_End": 130.0,
      "Text": " But the space has kind of grown exponentially, especially in the last year."
    },
    {
      "Time_Start": 130.0,
      "Time_End": 135.28,
      "Text": " There's a ton of existing research out there if you want to go take a look."
    },
    {
      "Time_Start": 135.28,
      "Time_End": 138.0,
      "Text": " But we're not going to do math today."
    },
    {
      "Time_Start": 138.0,
      "Time_End": 142.44,
      "Text": " But effectively, the fundamental truth of everything is everything is a function."
    },
    {
      "Time_Start": 142.44,
      "Time_End": 143.92000000000002,
      "Text": " And functions describe everything."
    },
    {
      "Time_Start": 143.92000000000002,
      "Time_End": 148.68,
      "Text": " So this is a great video."
    },
    {
      "Time_Start": 148.68,
      "Time_End": 149.68,
      "Text": " We're early in the talk."
    },
    {
      "Time_Start": 149.68,
      "Time_End": 150.68,
      "Text": " So I'm going to try and play it, actually."
    },
    {
      "Time_Start": 150.68,
      "Time_End": 151.68,
      "Text": " OK."
    },
    {
      "Time_Start": 151.68,
      "Time_End": 152.68,
      "Text": " Maybe not."
    },
    {
      "Time_Start": 152.68,
      "Time_End": 165.16,
      "Text": " But effectively, so he goes on to say functions"
    },
    {
      "Time_Start": 165.6,
      "Time_End": 166.6,
      "Text": " describe everything."
    },
    {
      "Time_Start": 166.6,
      "Time_End": 167.6,
      "Text": " He's very passionate."
    },
    {
      "Time_Start": 167.6,
      "Time_End": 168.6,
      "Text": " He's very passionate."
    },
    {
      "Time_Start": 168.6,
      "Time_End": 171.12,
      "Text": " A big professor energy, as we like to say."
    },
    {
      "Time_Start": 171.12,
      "Time_End": 175.28,
      "Text": " Yeah, but everything's a function."
    },
    {
      "Time_Start": 175.28,
      "Time_End": 180.48,
      "Text": " So he says the sound of my voice on your eardrums is a function."
    },
    {
      "Time_Start": 180.48,
      "Time_End": 182.68,
      "Text": " And everything in Active Directory is a function."
    },
    {
      "Time_Start": 182.68,
      "Time_End": 190.04,
      "Text": " So where we're used to looking at static graphs, we're going to go into some more dynamic things."
    },
    {
      "Time_Start": 190.04,
      "Time_End": 197.4,
      "Text": " But in terms of sort of, quote unquote, adversarial machine learning, it's very mathy."
    },
    {
      "Time_Start": 197.4,
      "Time_End": 202.0,
      "Text": " And when you first show up, you kind of think, oh, I need to look at these particular set"
    },
    {
      "Time_Start": 202.0,
      "Time_End": 204.88,
      "Text": " of algorithms that are adversarial in nature."
    },
    {
      "Time_Start": 204.88,
      "Time_End": 206.35999999999999,
      "Text": " So you might be an operator."
    },
    {
      "Time_Start": 206.35999999999999,
      "Time_End": 208.56,
      "Text": " You're like, OK, how do I attack this machine learning model?"
    },
    {
      "Time_Start": 208.56,
      "Time_End": 210.28,
      "Text": " And you're sort of like, OK, let me go Google it."
    },
    {
      "Time_Start": 210.28,
      "Time_End": 213.16,
      "Text": " And you show up with adversarial machine learning."
    },
    {
      "Time_Start": 213.16,
      "Time_End": 218.16,
      "Text": " But after a while, you sort of, well, yeah, after a few years, you sort of get this little"
    },
    {
      "Time_Start": 218.16,
      "Time_End": 221.2,
      "Text": " insight where it's like, adversarial is actually just an intent."
    },
    {
      "Time_Start": 221.2,
      "Time_End": 224.72,
      "Text": " So it doesn't really matter what sort of set of algorithms you want to use."
    },
    {
      "Time_Start": 224.72,
      "Time_End": 229.04,
      "Text": " It's really about that motivation behind how you use them."
    },
    {
      "Time_Start": 229.04,
      "Time_End": 235.12,
      "Text": " And I spend a lot of time sort of in two communities, in the machine learning community and in the"
    },
    {
      "Time_Start": 235.12,
      "Time_End": 236.96,
      "Text": " offensive security community."
    },
    {
      "Time_Start": 236.96,
      "Time_End": 241.2,
      "Text": " And one thing the machine learning community has maybe failed to understand so far is that"
    },
    {
      "Time_Start": 241.2,
      "Time_End": 243.64,
      "Text": " attackers are extremely smart."
    },
    {
      "Time_Start": 243.64,
      "Time_End": 244.8,
      "Text": " They're quick."
    },
    {
      "Time_Start": 244.8,
      "Time_End": 250.48000000000002,
      "Text": " They kind of don't care about the niceties and the formalities of research or writing"
    },
    {
      "Time_Start": 250.48000000000002,
      "Time_End": 251.48000000000002,
      "Text": " papers."
    },
    {
      "Time_Start": 251.48000000000002,
      "Time_End": 252.48000000000002,
      "Text": " They're very objective based."
    },
    {
      "Time_Start": 252.48000000000002,
      "Time_End": 255.74,
      "Text": " Like, they want to generate impact very quickly."
    },
    {
      "Time_Start": 255.74,
      "Time_End": 261.04,
      "Text": " And so as we go through, you can kind of see it with, I mean, chat GPT is a perfect example"
    },
    {
      "Time_Start": 261.04,
      "Time_End": 263.72,
      "Text": " where they sort of dropped it on the internet."
    },
    {
      "Time_Start": 263.72,
      "Time_End": 266.40000000000003,
      "Text": " And then we're like, oh, by the way, it can build bombs, right?"
    },
    {
      "Time_Start": 266.40000000000003,
      "Time_End": 270.56,
      "Text": " And you just wouldn't have that in the software world where Microsoft's going to drop a piece"
    },
    {
      "Time_Start": 270.56,
      "Time_End": 275.08,
      "Text": " of software and be like, oh, by the way, there's this like really bad, you know, code"
    },
    {
      "Time_Start": 275.08,
      "Time_End": 276.08,
      "Text": " execution in it."
    },
    {
      "Time_Start": 276.08,
      "Time_End": 278.88,
      "Text": " I mean, not on purpose, but they do, you know what I mean?"
    },
    {
      "Time_Start": 278.88,
      "Time_End": 284.52,
      "Text": " So there's always processes like before software is released where we have all this testing"
    },
    {
      "Time_Start": 284.52,
      "Time_End": 286.96,
      "Text": " and that just hasn't been the same in machine learning."
    },
    {
      "Time_Start": 286.96,
      "Time_End": 292.08,
      "Text": " I think it's a function of it coming from an academic space where they're not used to,"
    },
    {
      "Time_Start": 292.08,
      "Time_End": 297.16,
      "Text": " you know, living in a hostile environment such as the internet."
    },
    {
      "Time_Start": 297.36,
      "Time_End": 302.04,
      "Text": " You know, it being academically interesting is not necessarily operationally useful."
    },
    {
      "Time_Start": 302.04,
      "Time_End": 307.04,
      "Text": " And so when you go look at a lot of the research, like a default hop, skip, jump attack against"
    },
    {
      "Time_Start": 307.04,
      "Time_End": 313.8,
      "Text": " digits recognizer, which is the MNIST model, which is like your machine learning 101."
    },
    {
      "Time_Start": 313.8,
      "Time_End": 317.64000000000004,
      "Text": " The default number of queries for an attack out of ART, which is the Adversary Robustness"
    },
    {
      "Time_Start": 317.64000000000004,
      "Time_End": 320.58000000000004,
      "Text": " Toolbox, is like 25,000 queries."
    },
    {
      "Time_Start": 320.58000000000004,
      "Time_End": 325.16,
      "Text": " And so if you're going to try and run 25,000 queries against an online endpoint, like that's"
    },
    {
      "Time_Start": 325.16,
      "Time_End": 328.24,
      "Text": " just not operationally useful."
    },
    {
      "Time_Start": 328.24,
      "Time_End": 332.96000000000004,
      "Text": " And so there needs to be sort of this research iteration that we go through and, you know,"
    },
    {
      "Time_Start": 332.96000000000004,
      "Time_End": 339.48,
      "Text": " I kind of think as professors, as sort of exploit devs, where it's, you know, they come"
    },
    {
      "Time_Start": 339.48,
      "Time_End": 344.68,
      "Text": " up with the primitive and then it's sort of our job to operationalize it and make it useful."
    },
    {
      "Time_Start": 344.68,
      "Time_End": 348.14000000000004,
      "Text": " And we're kind of just starting to go through that."
    },
    {
      "Time_Start": 348.14000000000004,
      "Time_End": 350.64000000000004,
      "Text": " But yeah, I guess it is not all necessary about attacks."
    },
    {
      "Time_Start": 350.64000000000004,
      "Time_End": 354.04,
      "Text": " Like the defensive side also has as much to gain from it."
    },
    {
      "Time_Start": 354.08000000000004,
      "Time_End": 360.56,
      "Text": " So, you know, it being a capability exists in two realms, both offense and defense."
    },
    {
      "Time_Start": 364.56,
      "Time_End": 366.56,
      "Text": " Thank you, buddy."
    },
    {
      "Time_Start": 366.56,
      "Time_End": 371.8,
      "Text": " So yeah, the first place we're going to take a pit stop is offensive workflows."
    },
    {
      "Time_Start": 371.8,
      "Time_End": 376.56,
      "Text": " This is like the general term that we use to describe this process of using a model"
    },
    {
      "Time_Start": 376.56,
      "Time_End": 383.72,
      "Text": " to augment some, I don't know, directed graph of execution and tasks."
    },
    {
      "Time_Start": 384.40000000000003,
      "Time_End": 389.68,
      "Text": " And these are semi-synonymous with like evaluations for models, which is a little interesting."
    },
    {
      "Time_Start": 389.68,
      "Time_End": 393.28000000000003,
      "Text": " People want to know whether or not these models are dangerous, so they ask, can it hack things?"
    },
    {
      "Time_Start": 393.28000000000003,
      "Time_End": 396.20000000000005,
      "Text": " Now the natural conclusion you come to is, well, we have to make it do the thing that"
    },
    {
      "Time_Start": 396.20000000000005,
      "Time_End": 398.36,
      "Text": " you're scared of it doing."
    },
    {
      "Time_Start": 398.36,
      "Time_End": 403.96000000000004,
      "Text": " And really the only thing in our mind that separates a workflow from an evaluation of"
    },
    {
      "Time_Start": 403.96000000000004,
      "Time_End": 405.8,
      "Text": " a model is just metrics."
    },
    {
      "Time_Start": 405.8,
      "Time_End": 409.8,
      "Text": " Like a workflow is just having a model do a thing or using a model to do a thing."
    },
    {
      "Time_Start": 409.8,
      "Time_End": 413.08000000000004,
      "Text": " And an evaluation is just measuring how well the model did the thing."
    },
    {
      "Time_Start": 413.08,
      "Time_End": 415.0,
      "Text": " But you had to have the model do the thing in the first place."
    },
    {
      "Time_Start": 415.0,
      "Time_End": 418.96,
      "Text": " So you'll hear us use the term evals or workflows kind of interchangeably here."
    },
    {
      "Time_Start": 418.96,
      "Time_End": 422.8,
      "Text": " We view them as coming from the same core."
    },
    {
      "Time_Start": 422.8,
      "Time_End": 426.59999999999997,
      "Text": " Despite maybe pop culture, you know, over the past like six to eight months, I mean,"
    },
    {
      "Time_Start": 426.59999999999997,
      "Time_End": 428.08,
      "Text": " the last 12 months have been crazy."
    },
    {
      "Time_Start": 428.08,
      "Time_End": 432.44,
      "Text": " You know, for people like Will especially, like he's been doing security in the AI space"
    },
    {
      "Time_Start": 432.44,
      "Time_End": 435.84,
      "Text": " long before most people even knew what an LLM was, right?"
    },
    {
      "Time_Start": 435.84,
      "Time_End": 440.96,
      "Text": " Or had any concept of tokenization or, you know, neural networks."
    },
    {
      "Time_Start": 440.96000000000004,
      "Time_End": 443.92,
      "Text": " And yeah, these LLMs have kind of changed things up."
    },
    {
      "Time_Start": 443.92,
      "Time_End": 446.84000000000003,
      "Text": " And I think there was this immediate impression of, like, well, let's just try to have them"
    },
    {
      "Time_Start": 446.84000000000003,
      "Time_End": 452.96000000000004,
      "Text": " do either really dumb stuff like write phishing emails or give them extremely hard tasks."
    },
    {
      "Time_Start": 452.96000000000004,
      "Time_End": 456.44000000000005,
      "Text": " And when they fail at them, we'll just claim that these models aren't all that scary, right?"
    },
    {
      "Time_Start": 456.44000000000005,
      "Time_End": 462.44000000000005,
      "Text": " So the prevailing opinion is, like, oh, these models aren't quite very good at doing, you"
    },
    {
      "Time_Start": 462.44000000000005,
      "Time_End": 465.00000000000006,
      "Text": " know, attacks or offensive attacks or exploit research."
    },
    {
      "Time_Start": 465.00000000000006,
      "Time_End": 466.16,
      "Text": " And it's starting to change now."
    },
    {
      "Time_Start": 466.16,
      "Time_End": 468.40000000000003,
      "Text": " But the reality is they're actually quite capable."
    },
    {
      "Time_Start": 468.40000000000003,
      "Time_End": 472.48,
      "Text": " And there's a big middle ground for us between, like, the models being almost useless to being"
    },
    {
      "Time_Start": 472.48,
      "Time_End": 473.48,
      "Text": " completely autonomous."
    },
    {
      "Time_Start": 473.48,
      "Time_End": 474.48,
      "Text": " Right?"
    },
    {
      "Time_Start": 474.48,
      "Time_End": 476.84000000000003,
      "Text": " There's a lot of scaffolding that goes into the middle that I don't think people realize."
    },
    {
      "Time_Start": 476.84000000000003,
      "Time_End": 481.04,
      "Text": " It's like an engineering concept that a lot of the ML architects aren't as familiar with"
    },
    {
      "Time_Start": 481.04,
      "Time_End": 484.78000000000003,
      "Text": " because they're used to just having a model do a thing in isolation."
    },
    {
      "Time_Start": 484.78000000000003,
      "Time_End": 489.68000000000006,
      "Text": " But as attackers, we're used to taking a piece of technology and using it as a pure capability."
    },
    {
      "Time_Start": 489.68000000000006,
      "Time_End": 491.6,
      "Text": " So we're going to chat about a few different elements here."
    },
    {
      "Time_Start": 491.6,
      "Time_End": 494.64000000000004,
      "Text": " We're going to chat about, like, workflow orchestration platforms."
    },
    {
      "Time_Start": 494.64000000000004,
      "Time_End": 498.20000000000005,
      "Text": " We have an LLM interaction library called Rigging that we built specifically for this"
    },
    {
      "Time_Start": 498.2,
      "Time_End": 502.18,
      "Text": " process because we find a lot of the other libraries are really lacking in certain capabilities"
    },
    {
      "Time_Start": 502.18,
      "Time_End": 503.18,
      "Text": " we need."
    },
    {
      "Time_Start": 503.18,
      "Time_End": 505.12,
      "Text": " We'll look at tooling integrations."
    },
    {
      "Time_Start": 505.12,
      "Time_End": 508.03999999999996,
      "Text": " And then we'll chat a little bit about metrics when we get there."
    },
    {
      "Time_Start": 508.03999999999996,
      "Time_End": 511.96,
      "Text": " And we'll start with sort of this workflow or DAG platform question."
    },
    {
      "Time_Start": 511.96,
      "Time_End": 516.4,
      "Text": " This is a very well-developed space, usually in the data processing and pipelining."
    },
    {
      "Time_Start": 516.4,
      "Time_End": 518.2,
      "Text": " So, like, you know, imagine data science."
    },
    {
      "Time_Start": 518.2,
      "Time_End": 520.56,
      "Text": " You're processing, like, huge pandas data frames."
    },
    {
      "Time_Start": 520.56,
      "Time_End": 524.0,
      "Text": " There's a ton of platforms out there, like Luigi or Airflow, that try to make this process"
    },
    {
      "Time_Start": 524.0,
      "Time_End": 525.0,
      "Text": " pretty easy."
    },
    {
      "Time_Start": 525.16,
      "Time_End": 528.8,
      "Text": " And functionally, this is exactly the sort of platform that we want to use for these"
    },
    {
      "Time_Start": 528.8,
      "Time_End": 530.0,
      "Text": " offensive workflows."
    },
    {
      "Time_Start": 530.0,
      "Time_End": 533.12,
      "Text": " Because these models are really good at isolated tasks."
    },
    {
      "Time_Start": 533.12,
      "Time_End": 537.32,
      "Text": " And until we have, like, really advanced agent frameworks and those are well-developed, in"
    },
    {
      "Time_Start": 537.32,
      "Time_End": 540.36,
      "Text": " the meantime, we're going to have to kind of scaffold them into this process where we"
    },
    {
      "Time_Start": 540.36,
      "Time_End": 542.0,
      "Text": " give them a task and we capture results."
    },
    {
      "Time_Start": 542.0,
      "Time_End": 546.16,
      "Text": " And maybe we give it that task ten different times and capture all of those results and"
    },
    {
      "Time_Start": 546.16,
      "Time_End": 549.68,
      "Text": " try to, like, push them through a pipeline in a directed flow sort of way."
    },
    {
      "Time_Start": 549.68,
      "Time_End": 551.52,
      "Text": " So, yeah, we have a bunch listed up here."
    },
    {
      "Time_Start": 551.52,
      "Time_End": 553.16,
      "Text": " You're free to go and check them out."
    },
    {
      "Time_Start": 553.1999999999999,
      "Time_End": 557.88,
      "Text": " The one that we've sort of settled on that we're refactoring and building off of is Prefect."
    },
    {
      "Time_Start": 557.88,
      "Time_End": 561.16,
      "Text": " We also have our own library called Mark that I played around with, which is like a super"
    },
    {
      "Time_Start": 561.16,
      "Time_End": 564.56,
      "Text": " minimal Python flow library."
    },
    {
      "Time_Start": 564.56,
      "Time_End": 568.0,
      "Text": " But you can kind of get at the core of what we need, which is like individual isolated"
    },
    {
      "Time_Start": 568.0,
      "Time_End": 573.1999999999999,
      "Text": " execution steps where we have inputs, we're allowed to store outputs, potentially add"
    },
    {
      "Time_Start": 573.1999999999999,
      "Time_End": 576.4,
      "Text": " metrics or measurements onto those states."
    },
    {
      "Time_Start": 576.4,
      "Time_End": 580.4399999999999,
      "Text": " And then at the end, process something or read from other states."
    },
    {
      "Time_Start": 580.44,
      "Time_End": 584.7600000000001,
      "Text": " So this is what a pretty example or pretty basic example of Prefect calls look like."
    },
    {
      "Time_Start": 584.7600000000001,
      "Time_End": 586.7600000000001,
      "Text": " You functionally have two main components in Prefect."
    },
    {
      "Time_Start": 586.7600000000001,
      "Time_End": 588.96,
      "Text": " You have a flow and a task."
    },
    {
      "Time_Start": 588.96,
      "Time_End": 590.44,
      "Text": " Flows can call other flows."
    },
    {
      "Time_Start": 590.44,
      "Time_End": 591.8800000000001,
      "Text": " Flows can call tasks."
    },
    {
      "Time_Start": 591.8800000000001,
      "Time_End": 594.12,
      "Text": " Tasks can't call other tasks."
    },
    {
      "Time_Start": 594.12,
      "Time_End": 596.5600000000001,
      "Text": " But really, they're just decorators that get applied to functions."
    },
    {
      "Time_Start": 596.5600000000001,
      "Time_End": 599.72,
      "Text": " There's a whole underlying library system for it with persistent data storage."
    },
    {
      "Time_Start": 599.72,
      "Time_End": 600.72,
      "Text": " There's caching layers."
    },
    {
      "Time_Start": 600.72,
      "Time_End": 601.7600000000001,
      "Text": " There's retries."
    },
    {
      "Time_Start": 601.7600000000001,
      "Time_End": 605.08,
      "Text": " We write our own serializers so we can support the sorts of object types we want."
    },
    {
      "Time_Start": 605.08,
      "Time_End": 608.48,
      "Text": " And we make really heavy use of the caching layers throughout our workflows."
    },
    {
      "Time_Start": 608.52,
      "Time_End": 612.32,
      "Text": " So you might imagine you go and ask a model to take a task on something."
    },
    {
      "Time_Start": 612.32,
      "Time_End": 616.5600000000001,
      "Text": " You give the model that task and say, generate five different outputs for these one inputs."
    },
    {
      "Time_Start": 616.5600000000001,
      "Time_End": 618.04,
      "Text": " You cache all five of those outputs."
    },
    {
      "Time_Start": 618.04,
      "Time_End": 621.12,
      "Text": " And then every single time you want to use those outputs again, you simply pull them"
    },
    {
      "Time_Start": 621.12,
      "Time_End": 623.6800000000001,
      "Text": " off of the disk, deserialize them, and use them from the cache."
    },
    {
      "Time_Start": 623.6800000000001,
      "Time_End": 628.08,
      "Text": " So this makes the iterative process a lot easier, especially because in these LLM workflow"
    },
    {
      "Time_Start": 628.08,
      "Time_End": 632.32,
      "Text": " steps, you're oftentimes doing a lot of processing and a lot of model calls."
    },
    {
      "Time_Start": 632.32,
      "Time_End": 635.32,
      "Text": " And you're getting really deep into this flow, and you might be working at the end of the"
    },
    {
      "Time_Start": 635.32,
      "Time_End": 636.32,
      "Text": " flow."
    },
    {
      "Time_Start": 636.32,
      "Time_End": 639.88,
      "Text": " And then you have to wait for it to execute all of the original parts of the flow again."
    },
    {
      "Time_Start": 639.88,
      "Time_End": 643.88,
      "Text": " But yeah, we won't get too much into the details of Prefect."
    },
    {
      "Time_Start": 643.88,
      "Time_End": 647.2800000000001,
      "Text": " But these are really cool tools that I don't think have been heavily used in security."
    },
    {
      "Time_Start": 647.2800000000001,
      "Time_End": 652.72,
      "Text": " I know there was some commentary about using them for XPEN resources or doing recon with"
    },
    {
      "Time_Start": 652.72,
      "Time_End": 655.4000000000001,
      "Text": " them using these sorts of workflow platforms."
    },
    {
      "Time_Start": 655.4000000000001,
      "Time_End": 658.08,
      "Text": " But they work really well for interacting with these models."
    },
    {
      "Time_Start": 658.08,
      "Time_End": 660.8000000000001,
      "Text": " This is a couple of code examples from our rigging library."
    },
    {
      "Time_Start": 660.8000000000001,
      "Time_End": 666.24,
      "Text": " Like I said, you're probably familiar with LLAMA index or Lang chain."
    },
    {
      "Time_Start": 666.24,
      "Time_End": 667.6,
      "Text": " There's maybe DSPY."
    },
    {
      "Time_Start": 667.6,
      "Time_End": 671.28,
      "Text": " There's a lot of libraries that try to make interacting with these LLMs easy."
    },
    {
      "Time_Start": 671.28,
      "Time_End": 673.44,
      "Text": " There's a few things that I think they suck at."
    },
    {
      "Time_Start": 673.44,
      "Time_End": 677.36,
      "Text": " One is they tend to over-prefer JSON, which models are terrible at."
    },
    {
      "Time_Start": 677.36,
      "Time_End": 680.5600000000001,
      "Text": " And actually, Anthropic is a smart group, and they knew this a long time ago, which"
    },
    {
      "Time_Start": 680.5600000000001,
      "Time_End": 685.44,
      "Text": " is why when you go to look up how do you use Cloud, their best practice recommendations"
    },
    {
      "Time_Start": 685.44,
      "Time_End": 690.36,
      "Text": " is use XML tags, because XML tags can flow freely in semi-structured text."
    },
    {
      "Time_Start": 690.36,
      "Time_End": 693.6800000000001,
      "Text": " When you use JSON, the entire message has to be JSON."
    },
    {
      "Time_Start": 693.6800000000001,
      "Time_End": 697.1200000000001,
      "Text": " And JSON involves a lot of escaping as well, which is not natural text that models have"
    },
    {
      "Time_Start": 697.1200000000001,
      "Time_End": 698.2800000000001,
      "Text": " been exposed to."
    },
    {
      "Time_Start": 698.2800000000001,
      "Time_End": 701.5200000000001,
      "Text": " So we have this meme that we sent on our chat the other day of a guy throwing a stick in"
    },
    {
      "Time_Start": 701.5200000000001,
      "Time_End": 702.6800000000001,
      "Text": " front of his bicycle wheel."
    },
    {
      "Time_Start": 702.6800000000001,
      "Time_End": 705.6800000000001,
      "Text": " And it's like, oh, I need structured output for my model."
    },
    {
      "Time_Start": 705.6800000000001,
      "Time_End": 709.4000000000001,
      "Text": " You quote, only return your response in valid JSON, and then the model fails, and you're"
    },
    {
      "Time_Start": 709.4000000000001,
      "Time_End": 710.4000000000001,
      "Text": " like, oh, this model sucks."
    },
    {
      "Time_Start": 710.4000000000001,
      "Time_End": 711.5200000000001,
      "Text": " It's like, no, you suck."
    },
    {
      "Time_Start": 711.5200000000001,
      "Time_End": 714.08,
      "Text": " You asked the model to do something it's not very good at."
    },
    {
      "Time_Start": 714.08,
      "Time_End": 716.5200000000001,
      "Text": " So we tend to prefer XML underneath."
    },
    {
      "Time_Start": 716.5200000000001,
      "Time_End": 720.0400000000001,
      "Text": " The underlying framework that this is based on is light LLM."
    },
    {
      "Time_Start": 720.0400000000001,
      "Time_End": 722.2,
      "Text": " So we can access all of the major model providers."
    },
    {
      "Time_Start": 722.2,
      "Time_End": 725.2800000000001,
      "Text": " You can hook up to custom open API servers."
    },
    {
      "Time_Start": 725.2800000000001,
      "Time_End": 730.44,
      "Text": " And we use a syntax similar to connection strings for databases."
    },
    {
      "Time_Start": 730.44,
      "Time_End": 733.6400000000001,
      "Text": " So you effectively call this get generator, and you spec a connection string out with"
    },
    {
      "Time_Start": 733.6400000000001,
      "Time_End": 735.2800000000001,
      "Text": " all the arguments for your model."
    },
    {
      "Time_Start": 735.2800000000001,
      "Time_End": 736.9200000000001,
      "Text": " There's no kwargs."
    },
    {
      "Time_Start": 736.9200000000001,
      "Time_End": 742.2,
      "Text": " There's no millions of arguments and parameters that you can pass to these models."
    },
    {
      "Time_Start": 742.2,
      "Time_End": 745.36,
      "Text": " It's just a single string that defines, do I want to use Mistral, do I want to use GPT,"
    },
    {
      "Time_Start": 745.36,
      "Time_End": 749.12,
      "Text": " do I want to use my own custom server, do I want to use a Hugging Face endpoint?"
    },
    {
      "Time_Start": 749.12,
      "Time_End": 751.9200000000001,
      "Text": " And yeah, the generator, call chat on it."
    },
    {
      "Time_Start": 751.92,
      "Time_End": 753.52,
      "Text": " You get back this chat object."
    },
    {
      "Time_Start": 753.52,
      "Time_End": 755.5999999999999,
      "Text": " We can do things like structured model parsing."
    },
    {
      "Time_Start": 755.5999999999999,
      "Time_End": 758.4399999999999,
      "Text": " So we have a core model that's based on Pydantic XML."
    },
    {
      "Time_Start": 758.4399999999999,
      "Time_End": 764.52,
      "Text": " You can define these models and then effectively ask an LLM to produce text that parses into"
    },
    {
      "Time_Start": 764.52,
      "Time_End": 765.8,
      "Text": " that model."
    },
    {
      "Time_Start": 765.8,
      "Time_End": 770.4799999999999,
      "Text": " The code itself will effectively extract out the XML from the text regardless of where"
    },
    {
      "Time_Start": 770.4799999999999,
      "Time_End": 771.4799999999999,
      "Text": " it is."
    },
    {
      "Time_Start": 771.4799999999999,
      "Time_End": 774.3199999999999,
      "Text": " And it actually tries to be very smart about identifying times where the model might produce"
    },
    {
      "Time_Start": 774.3199999999999,
      "Time_End": 778.74,
      "Text": " like a partial matching tag versus a full matching tag."
    },
    {
      "Time_Start": 778.74,
      "Time_End": 783.14,
      "Text": " And underneath these message objects get effectively converted into parsed messages"
    },
    {
      "Time_Start": 783.14,
      "Time_End": 784.86,
      "Text": " where you have the individual parts."
    },
    {
      "Time_Start": 784.86,
      "Time_End": 786.1,
      "Text": " These models can be nested."
    },
    {
      "Time_Start": 786.1,
      "Time_End": 788.34,
      "Text": " You can have XML models inside of XML models."
    },
    {
      "Time_Start": 788.34,
      "Time_End": 792.46,
      "Text": " We have tool calling structures that use this XML calling structure underneath."
    },
    {
      "Time_Start": 792.46,
      "Time_End": 794.82,
      "Text": " And this works without the model needing to be trained on it."
    },
    {
      "Time_Start": 794.82,
      "Time_End": 795.82,
      "Text": " People make a big deal about this."
    },
    {
      "Time_Start": 795.82,
      "Time_End": 798.62,
      "Text": " They'll say, oh, my model's not trained to do JSON tool calling."
    },
    {
      "Time_Start": 798.62,
      "Time_End": 799.62,
      "Text": " You don't need it."
    },
    {
      "Time_Start": 799.62,
      "Time_End": 802.14,
      "Text": " Use a format that the models understand well."
    },
    {
      "Time_Start": 802.14,
      "Time_End": 806.82,
      "Text": " We can get effectively tool calling successfully in all the vanilla models, even down to like"
    },
    {
      "Time_Start": 806.82,
      "Time_End": 810.2600000000001,
      "Text": " Mistral small, without it needing to be trained on it."
    },
    {
      "Time_Start": 810.2600000000001,
      "Time_End": 814.94,
      "Text": " So in this particular case, that using call will trigger underneath a XML schema to be"
    },
    {
      "Time_Start": 814.94,
      "Time_End": 819.2600000000001,
      "Text": " dynamically created from the type hints on this class, passed into the model, and the"
    },
    {
      "Time_Start": 819.2600000000001,
      "Time_End": 822.0200000000001,
      "Text": " model is allowed to execute them, and all the calls will be validated and passed off"
    },
    {
      "Time_Start": 822.0200000000001,
      "Time_End": 823.0200000000001,
      "Text": " to your class."
    },
    {
      "Time_Start": 823.0200000000001,
      "Time_End": 824.34,
      "Text": " It's all modern Python code."
    },
    {
      "Time_Start": 824.34,
      "Time_End": 828.38,
      "Text": " I have no space for Python 2.7 old nonsense."
    },
    {
      "Time_Start": 828.38,
      "Time_End": 834.5400000000001,
      "Text": " So type hinting, schema validation, you know, type dictionaries, all of the stuff that you"
    },
    {
      "Time_Start": 834.54,
      "Time_End": 837.66,
      "Text": " would expect from modern Python classes."
    },
    {
      "Time_Start": 837.66,
      "Time_End": 841.8199999999999,
      "Text": " We do retry max if we want to force the model to parse into a class before we continue,"
    },
    {
      "Time_Start": 841.8199999999999,
      "Time_End": 843.5799999999999,
      "Text": " and it will error out if it can't."
    },
    {
      "Time_Start": 843.5799999999999,
      "Time_End": 846.26,
      "Text": " So this is really helpful when we're working in workflows where we don't have to use regex"
    },
    {
      "Time_Start": 846.26,
      "Time_End": 850.26,
      "Text": " strings and we don't have to handle cases where there was a partial match or maybe the"
    },
    {
      "Time_Start": 850.26,
      "Time_End": 853.62,
      "Text": " text of the message didn't entirely match the model we wanted."
    },
    {
      "Time_Start": 853.62,
      "Time_End": 856.5799999999999,
      "Text": " And then ultimately this culminates, and Will's going to go through a demo for Bloodhound,"
    },
    {
      "Time_Start": 856.5799999999999,
      "Time_End": 861.3,
      "Text": " but we have some screenshots here of like what this whole main sale, prefect, rigging"
    },
    {
      "Time_Start": 861.3000000000001,
      "Time_End": 865.94,
      "Text": " looks like for something as simple as like automated vulnerability triage."
    },
    {
      "Time_Start": 865.94,
      "Time_End": 871.7,
      "Text": " We effectively took use cases like .NET reversing, we built tooling calls in so the model has"
    },
    {
      "Time_Start": 871.7,
      "Time_End": 875.7400000000001,
      "Text": " access to reversing .NET code and getting information about call flows, and we effectively"
    },
    {
      "Time_Start": 875.7400000000001,
      "Time_End": 879.6200000000001,
      "Text": " walk it through the process saying, I want to find deserialization vulnerabilities in"
    },
    {
      "Time_Start": 879.6200000000001,
      "Time_End": 884.98,
      "Text": " these files, and it goes through a whole workflow process that's, I don't know, probably three"
    },
    {
      "Time_Start": 884.98,
      "Time_End": 890.7800000000001,
      "Text": " subflows and eight task steps deep, and it will turn out writing you exact exploit instructions"
    },
    {
      "Time_Start": 890.78,
      "Time_End": 895.06,
      "Text": " with full details on how to build payloads and how to run them on hosts with very little"
    },
    {
      "Time_Start": 895.06,
      "Time_End": 896.3,
      "Text": " scaffolding."
    },
    {
      "Time_Start": 896.3,
      "Time_End": 898.86,
      "Text": " And this is the sort of stuff that people didn't think is possible, and if you go and"
    },
    {
      "Time_Start": 898.86,
      "Time_End": 902.62,
      "Text": " read Twitter, they would say, oh, these models aren't that great because I tried to prompt,"
    },
    {
      "Time_Start": 902.62,
      "Time_End": 906.8199999999999,
      "Text": " you know, GPT in a workbench and it didn't do the thing, but yeah, if you put the engineering"
    },
    {
      "Time_Start": 906.8199999999999,
      "Time_End": 911.1,
      "Text": " time in, these models can do pretty incredible things, which is what our goal are."
    },
    {
      "Time_Start": 911.1,
      "Time_End": 912.1,
      "Text": " And here's kind of an output."
    },
    {
      "Time_Start": 912.1,
      "Time_End": 915.66,
      "Text": " So like this is a connection string for Mistral, this is Mistral scoring that we have metrics"
    },
    {
      "Time_Start": 915.66,
      "Time_End": 919.4599999999999,
      "Text": " assigned to all of these subphases, and this is effectively how we measure how well models"
    },
    {
      "Time_Start": 919.46,
      "Time_End": 922.1,
      "Text": " perform at all these functions."
    },
    {
      "Time_Start": 922.1,
      "Time_End": 925.94,
      "Text": " And we can do things like perform multiple iterations, so for any sub-step, we perform"
    },
    {
      "Time_Start": 925.94,
      "Time_End": 929.5400000000001,
      "Text": " it five different times to balance out the stochastic nature of the models, because we"
    },
    {
      "Time_Start": 929.5400000000001,
      "Time_End": 934.58,
      "Text": " know that they might behave slightly differently on one generation over another."
    },
    {
      "Time_Start": 934.58,
      "Time_End": 936.5,
      "Text": " So box over, I'll hand it back to Will."
    },
    {
      "Time_Start": 936.5,
      "Time_End": 937.5,
      "Text": " Nice."
    },
    {
      "Time_Start": 937.5,
      "Time_End": 939.98,
      "Text": " Okay, so now we're going to go talk through Bloodhound."
    },
    {
      "Time_Start": 939.98,
      "Time_End": 945.7800000000001,
      "Text": " So this is obviously a conference about graphs, and Bloodhound is a graph, and, you know,"
    },
    {
      "Time_Start": 945.7800000000001,
      "Time_End": 948.4200000000001,
      "Text": " this execution flows are also graphs."
    },
    {
      "Time_Start": 948.4200000000001,
      "Time_End": 955.2,
      "Text": " So if you imagine a lot of the Caldera-type workflows are sort of, you have dependencies"
    },
    {
      "Time_Start": 955.2,
      "Time_End": 960.7400000000001,
      "Text": " that need to be met before you can run other particular tasks, things like that."
    },
    {
      "Time_Start": 960.7400000000001,
      "Time_End": 966.58,
      "Text": " But here's sort of like a scenario that you might look like, and fairly common."
    },
    {
      "Time_Start": 966.58,
      "Time_End": 970.5600000000001,
      "Text": " So I use the, there's a project called AD Simulator."
    },
    {
      "Time_Start": 970.5600000000001,
      "Time_End": 977.0600000000001,
      "Text": " It's kind of an older project, but it'll effectively create Active Directory environments for us,"
    },
    {
      "Time_Start": 977.0600000000001,
      "Time_End": 980.94,
      "Text": " so, you know, we don't really op like we used to, so we're not in and out of networks."
    },
    {
      "Time_Start": 980.94,
      "Time_End": 984.1,
      "Text": " We need to kind of build our own environments these days."
    },
    {
      "Time_Start": 984.1,
      "Time_End": 989.5000000000001,
      "Text": " But this is a fairly common relationship."
    },
    {
      "Time_Start": 989.5000000000001,
      "Time_End": 997.84,
      "Text": " And then just kind of as a joke, I put this exact little relationship into Claude and"
    },
    {
      "Time_Start": 997.84,
      "Time_End": 1002.5400000000001,
      "Text": " asked it to build me a math function for it, and this is what it came up with."
    },
    {
      "Time_Start": 1002.5400000000001,
      "Time_End": 1005.74,
      "Text": " And this is what, like, maybe a lot of the academic lectures would be."
    },
    {
      "Time_Start": 1005.74,
      "Time_End": 1010.82,
      "Text": " So if you're, like, reading papers and things, it's not like it's a different language so"
    },
    {
      "Time_Start": 1010.82,
      "Time_End": 1015.7,
      "Text": " much as it is just academic formality, where they have to, like, sort of deconstruct everything"
    },
    {
      "Time_Start": 1015.7,
      "Time_End": 1017.7,
      "Text": " and then put it back together."
    },
    {
      "Time_Start": 1017.7,
      "Time_End": 1020.5,
      "Text": " I'm not going to read all this, but you can look through it, and you'll be like, oh, yeah,"
    },
    {
      "Time_Start": 1020.5,
      "Time_End": 1021.9,
      "Text": " that, like, totally makes sense."
    },
    {
      "Time_Start": 1021.9,
      "Time_End": 1027.86,
      "Text": " And I think it just takes a while for, you know, it just takes a while for it to, like,"
    },
    {
      "Time_Start": 1027.86,
      "Time_End": 1030.54,
      "Text": " I don't know, seep in or whatever."
    },
    {
      "Time_Start": 1030.54,
      "Time_End": 1038.5,
      "Text": " But yeah, this paper or this little snippet is exactly describing this in math."
    },
    {
      "Time_Start": 1038.5,
      "Time_End": 1043.78,
      "Text": " So the result of this, whatever this would be, is just a vector of 0s and 1s that are"
    },
    {
      "Time_Start": 1043.78,
      "Time_End": 1048.5,
      "Text": " true and false if the condition is true."
    },
    {
      "Time_Start": 1048.5,
      "Time_End": 1049.5,
      "Text": " So where is it?"
    },
    {
      "Time_Start": 1049.5,
      "Time_End": 1050.5,
      "Text": " Yeah, there you go."
    },
    {
      "Time_Start": 1050.5,
      "Time_End": 1055.46,
      "Text": " If the expression evaluates to 1 for a user UI in a group GJ, the corresponding position"
    },
    {
      "Time_Start": 1055.46,
      "Time_End": 1059.78,
      "Text": " IJ in the matrix V will be set to 1, right?"
    },
    {
      "Time_Start": 1059.78,
      "Time_End": 1063.26,
      "Text": " And that's just saying this."
    },
    {
      "Time_Start": 1063.26,
      "Time_End": 1067.42,
      "Text": " And so as you, like, jump into archive, like, you just have to understand that, like, they're"
    },
    {
      "Time_Start": 1067.42,
      "Time_End": 1069.86,
      "Text": " not writing paper they're not writing papers for you."
    },
    {
      "Time_Start": 1069.86,
      "Time_End": 1073.46,
      "Text": " They're writing papers for their peers who are not you."
    },
    {
      "Time_Start": 1073.46,
      "Time_End": 1078.62,
      "Text": " But, like, you can take that in and sort of translate it to your own sort of language."
    },
    {
      "Time_Start": 1078.62,
      "Time_End": 1082.06,
      "Text": " And I, you know, and this was done with Claude 3 or Claude."
    },
    {
      "Time_Start": 1082.06,
      "Time_End": 1087.22,
      "Text": " So I think LLMs are kind of these universal translators, right, where you can take any"
    },
    {
      "Time_Start": 1087.22,
      "Time_End": 1090.1000000000001,
      "Text": " Python function and be like, oh, I want to write this in Go now."
    },
    {
      "Time_Start": 1090.1000000000001,
      "Time_End": 1091.34,
      "Text": " I want to write this in Nim."
    },
    {
      "Time_Start": 1091.34,
      "Time_End": 1094.8600000000001,
      "Text": " I want to write this in, you know, whatever language you want."
    },
    {
      "Time_Start": 1094.8600000000001,
      "Time_End": 1099.9,
      "Text": " That's tend to how I kind of use them."
    },
    {
      "Time_Start": 1099.9,
      "Time_End": 1103.6200000000001,
      "Text": " But obviously, you know, the implication of the relationship is that, you know, a user"
    },
    {
      "Time_Start": 1103.6200000000001,
      "Time_End": 1111.34,
      "Text": " can log into the host and we get creds potentially, which means we can maybe move on."
    },
    {
      "Time_Start": 1111.34,
      "Time_End": 1114.74,
      "Text": " So when you're looking at prompting a model, you kind of want to parameterize these things."
    },
    {
      "Time_Start": 1114.78,
      "Time_End": 1119.42,
      "Text": " So, you know, if you know you're looking for a user, okay, so you're logged in as a user."
    },
    {
      "Time_Start": 1119.42,
      "Time_End": 1124.66,
      "Text": " Please look at these outgoing relationships and return a list."
    },
    {
      "Time_Start": 1124.66,
      "Time_End": 1128.9,
      "Text": " And then, you know, here's $20 and a scratch off just so it knows that it's an important"
    },
    {
      "Time_Start": 1128.9,
      "Time_End": 1133.54,
      "Text": " job and there's a reward at the end."
    },
    {
      "Time_Start": 1133.54,
      "Time_End": 1137.18,
      "Text": " Or you could do, like, look at this relationship and tell me if it's exploitable."
    },
    {
      "Time_Start": 1137.18,
      "Time_End": 1142.22,
      "Text": " So in one case, you're giving it a whole list of relationships and asking it to return just"
    },
    {
      "Time_Start": 1142.22,
      "Time_End": 1143.22,
      "Text": " one."
    },
    {
      "Time_Start": 1143.22,
      "Time_End": 1147.54,
      "Text": " So of a list where you're saying you're just giving the model more control versus saying,"
    },
    {
      "Time_Start": 1147.54,
      "Time_End": 1149.82,
      "Text": " hey, here's a single relationship."
    },
    {
      "Time_Start": 1149.82,
      "Time_End": 1153.22,
      "Text": " Please tell me if this is exploitable."
    },
    {
      "Time_Start": 1153.22,
      "Time_End": 1158.22,
      "Text": " And I think it has to, you know, the success of the model has to do with it being task"
    },
    {
      "Time_Start": 1158.22,
      "Time_End": 1162.58,
      "Text": " specific, but also the amount of information and context you give it."
    },
    {
      "Time_Start": 1162.58,
      "Time_End": 1167.94,
      "Text": " And so, I mean, it was up until very recently that, you know, these longer context models"
    },
    {
      "Time_Start": 1167.94,
      "Time_End": 1169.38,
      "Text": " weren't being released."
    },
    {
      "Time_Start": 1169.38,
      "Time_End": 1174.8200000000002,
      "Text": " I mean, T5 had it for a while, but, you know, chat GPT or the transformer architecture kind"
    },
    {
      "Time_Start": 1174.8200000000002,
      "Time_End": 1178.7800000000002,
      "Text": " of took over the news cycles."
    },
    {
      "Time_Start": 1178.7800000000002,
      "Time_End": 1182.5400000000002,
      "Text": " But really, you get to decide, you know, and you should, what you should be doing is evaluating"
    },
    {
      "Time_Start": 1182.5400000000002,
      "Time_End": 1188.0200000000002,
      "Text": " each path, whether it's, you know, a list of things or just singular."
    },
    {
      "Time_Start": 1188.0200000000002,
      "Time_End": 1193.3200000000002,
      "Text": " And I think we prefer to do the singular, so smaller tasks it tends to be better at."
    },
    {
      "Time_Start": 1193.3200000000002,
      "Time_End": 1197.22,
      "Text": " But I think that that might change into the future, but it's just, you know, it's easier"
    },
    {
      "Time_Start": 1197.22,
      "Time_End": 1199.9,
      "Text": " to deal with smaller pieces of information, I think, as a human."
    },
    {
      "Time_Start": 1199.9,
      "Time_End": 1204.8600000000001,
      "Text": " So even as context lengths get larger, there's still going to be like this aspect of you"
    },
    {
      "Time_Start": 1204.8600000000001,
      "Time_End": 1211.3,
      "Text": " needing to filter at that scale to make it useful for you."
    },
    {
      "Time_Start": 1211.3,
      "Time_End": 1212.58,
      "Text": " And that's effectively what this says."
    },
    {
      "Time_Start": 1212.58,
      "Time_End": 1218.46,
      "Text": " So, you know, we're going to get a starting user and then, you know, you can get all users"
    },
    {
      "Time_Start": 1218.46,
      "Time_End": 1220.3,
      "Text": " and then you can get user relationships."
    },
    {
      "Time_Start": 1220.3,
      "Time_End": 1227.86,
      "Text": " And these are all tasks that get separated out and they just, they run in this order."
    },
    {
      "Time_Start": 1227.86,
      "Time_End": 1232.54,
      "Text": " I guess you put them up as a workflow, but we have like a tool here, which is our Bloodhound"
    },
    {
      "Time_Start": 1232.54,
      "Time_End": 1236.1399999999999,
      "Text": " Cypher client, then we just add a username."
    },
    {
      "Time_Start": 1236.1399999999999,
      "Time_End": 1238.94,
      "Text": " And then you can go through and just, you know, get all the information you need in"
    },
    {
      "Time_Start": 1238.94,
      "Time_End": 1243.22,
      "Text": " a task as if it were like an ETL or a data science pipeline."
    },
    {
      "Time_Start": 1243.22,
      "Time_End": 1247.62,
      "Text": " If you think about sort of a network, you know, at Silent Break, we wrote a lot of custom"
    },
    {
      "Time_Start": 1247.6200000000001,
      "Time_End": 1251.7800000000002,
      "Text": " tools and the first thing anyone ever did there when they joined was try and write their"
    },
    {
      "Time_Start": 1251.7800000000002,
      "Time_End": 1256.18,
      "Text": " own piece of malware until they, and which was successful until they realized at some"
    },
    {
      "Time_Start": 1256.18,
      "Time_End": 1265.98,
      "Text": " point you just become a software dev punching tickets doing feature improvements, sorry."
    },
    {
      "Time_Start": 1265.98,
      "Time_End": 1273.5800000000002,
      "Text": " But so the sort of the bit you realize that malware is just sort of a server client relationship"
    },
    {
      "Time_Start": 1273.58,
      "Time_End": 1279.22,
      "Text": " and you're not maybe different than, I don't know, whatever server client relationship,"
    },
    {
      "Time_Start": 1279.22,
      "Time_End": 1281.1,
      "Text": " like it's an abstraction."
    },
    {
      "Time_Start": 1281.1,
      "Time_End": 1283.3,
      "Text": " It's the same with these task flows."
    },
    {
      "Time_Start": 1283.3,
      "Time_End": 1289.1,
      "Text": " So if you think about like a C2 pipe, it kind of becomes just you're querying a database,"
    },
    {
      "Time_Start": 1289.1,
      "Time_End": 1292.4199999999998,
      "Text": " but that database just happens to be a network, right?"
    },
    {
      "Time_Start": 1292.4199999999998,
      "Time_End": 1293.4199999999998,
      "Text": " That just happens to be."
    },
    {
      "Time_Start": 1293.4199999999998,
      "Time_End": 1294.74,
      "Text": " So it's like you have this pipe in and out."
    },
    {
      "Time_Start": 1294.74,
      "Time_End": 1299.96,
      "Text": " So why wouldn't you sort of build these MLOps pipelines around that flow of traffic and"
    },
    {
      "Time_Start": 1299.96,
      "Time_End": 1303.26,
      "Text": " sort of learn or, you know, do whatever you want, process data."
    },
    {
      "Time_Start": 1303.94,
      "Time_End": 1308.34,
      "Text": " And we think we kind of are like the nemesis project is kind of is towards that where we're"
    },
    {
      "Time_Start": 1308.34,
      "Time_End": 1312.7,
      "Text": " starting to like keep things offline and being able to query them so we don't have to re-query"
    },
    {
      "Time_Start": 1312.7,
      "Time_End": 1313.7,
      "Text": " networks."
    },
    {
      "Time_Start": 1313.7,
      "Time_End": 1318.18,
      "Text": " And you can kind of see that in some archive papers."
    },
    {
      "Time_Start": 1318.18,
      "Time_End": 1322.42,
      "Text": " Anyway, that's a different talk."
    },
    {
      "Time_Start": 1322.42,
      "Time_End": 1327.06,
      "Text": " And so we basically go through and we give it all of this information and so we just"
    },
    {
      "Time_Start": 1327.06,
      "Time_End": 1329.98,
      "Text": " ask it, is this relationship exploitable?"
    },
    {
      "Time_Start": 1329.98,
      "Time_End": 1334.38,
      "Text": " You can kind of see we have our prompt here where we just have an IT admin system prompt"
    },
    {
      "Time_Start": 1334.38,
      "Time_End": 1340.66,
      "Text": " and it's like you are an IT admin responsible for managing Active Directory control relationships."
    },
    {
      "Time_Start": 1340.66,
      "Time_End": 1344.1,
      "Text": " That kind of gives it a persona, tells it who it is."
    },
    {
      "Time_Start": 1344.1,
      "Time_End": 1345.7,
      "Text": " And then you say, is this path exploitable?"
    },
    {
      "Time_Start": 1345.7,
      "Time_End": 1350.06,
      "Text": " You give it a username and the relationship and the relationship is just that member of"
    },
    {
      "Time_Start": 1350.06,
      "Time_End": 1352.9,
      "Text": " JSON structure."
    },
    {
      "Time_Start": 1352.9,
      "Time_End": 1356.9,
      "Text": " And then maybe that's kind of lazy, but, you know, these models are pretty good."
    },
    {
      "Time_Start": 1356.9,
      "Time_End": 1361.26,
      "Text": " And so I kind of start with lazy and then just work my way up until there's a point"
    },
    {
      "Time_Start": 1361.26,
      "Time_End": 1369.9,
      "Text": " where it works or, you know, it starts the metrics become a little more stable, a little"
    },
    {
      "Time_Start": 1369.9,
      "Time_End": 1372.3000000000002,
      "Text": " less stochastic or erratic."
    },
    {
      "Time_Start": 1372.3000000000002,
      "Time_End": 1375.26,
      "Text": " And then we use the rigging framework to just parse it as a yes, no."
    },
    {
      "Time_Start": 1375.26,
      "Time_End": 1380.74,
      "Text": " So this gives us a nice binary check of is this relationship exploitable, yes or no."
    },
    {
      "Time_Start": 1380.74,
      "Time_End": 1382.38,
      "Text": " If yes, go on to the next step."
    },
    {
      "Time_Start": 1382.38,
      "Time_End": 1388.14,
      "Text": " If no, we're moving on."
    },
    {
      "Time_Start": 1388.14,
      "Time_End": 1395.42,
      "Text": " And I think the core thing here is just, you know, being tasked up versus model down."
    },
    {
      "Time_Start": 1395.42,
      "Time_End": 1399.0600000000002,
      "Text": " And then at the bottom here, just giving help docs to the model."
    },
    {
      "Time_Start": 1399.0600000000002,
      "Time_End": 1402.7800000000002,
      "Text": " And so, you know, do, you know, whack help or tac-tac help."
    },
    {
      "Time_Start": 1402.7800000000002,
      "Time_End": 1406.5400000000002,
      "Text": " And then just saying, hey, you're using this tool, here are these help docs."
    },
    {
      "Time_Start": 1406.5400000000002,
      "Time_End": 1409.38,
      "Text": " This is the context you need to use."
    },
    {
      "Time_Start": 1409.38,
      "Time_End": 1414.66,
      "Text": " And just helping guide the model onto your target, whichever, whatever that is."
    },
    {
      "Time_Start": 1414.66,
      "Time_End": 1417.38,
      "Text": " And you can do sort of, you know, tool calling."
    },
    {
      "Time_Start": 1417.38,
      "Time_End": 1419.1000000000001,
      "Text": " There's a lot of examples of people doing that."
    },
    {
      "Time_Start": 1419.1000000000001,
      "Time_End": 1422.94,
      "Text": " I'd say typically people call functions rather than tools, but."
    },
    {
      "Time_Start": 1422.94,
      "Time_End": 1426.8200000000002,
      "Text": " And so, as I say, operators, like, are tasked up."
    },
    {
      "Time_Start": 1426.8200000000002,
      "Time_End": 1432.2600000000002,
      "Text": " So we care about, we prefer build scaffolding and then remove it as the models get better"
    },
    {
      "Time_Start": 1432.2600000000002,
      "Time_End": 1434.8200000000002,
      "Text": " because we have stability as a requirement, right?"
    },
    {
      "Time_Start": 1434.82,
      "Time_End": 1443.1,
      "Text": " Like one of the, I guess the axioms of one of the talks was in, besides Las Vegas with"
    },
    {
      "Time_Start": 1443.1,
      "Time_End": 1444.1,
      "Text": " OpBot."
    },
    {
      "Time_Start": 1444.1,
      "Time_End": 1449.26,
      "Text": " One of the axioms, so the first, I think the first place people go here in this space is"
    },
    {
      "Time_Start": 1449.26,
      "Time_End": 1450.78,
      "Text": " like reinforcement learning."
    },
    {
      "Time_Start": 1450.78,
      "Time_End": 1454.82,
      "Text": " They're like, oh, you know, if I can just give it enough information, I can have a model"
    },
    {
      "Time_Start": 1454.82,
      "Time_End": 1460.02,
      "Text": " learn like what actions do best in what states, then, you know, let's do that."
    },
    {
      "Time_Start": 1460.02,
      "Time_End": 1464.54,
      "Text": " But you can't have sort of, you can't drop an agent."
    },
    {
      "Time_Start": 1464.54,
      "Time_End": 1467.26,
      "Text": " You can't drop an RL agent on a network and have it learn."
    },
    {
      "Time_Start": 1467.26,
      "Time_End": 1473.02,
      "Text": " Like it needs to know, you know, what it needs to know when you drop it because of the, as"
    },
    {
      "Time_Start": 1473.02,
      "Time_End": 1474.3799999999999,
      "Text": " a function of, you know, operation."
    },
    {
      "Time_Start": 1474.3799999999999,
      "Time_End": 1479.18,
      "Text": " You can't just, you know, drop an agent on a network and have it go like query stuff"
    },
    {
      "Time_Start": 1479.18,
      "Time_End": 1483.3,
      "Text": " and fail and generate a bunch of logs."
    },
    {
      "Time_Start": 1483.3,
      "Time_End": 1484.3,
      "Text": " So we have stability as a requirement."
    },
    {
      "Time_Start": 1484.3,
      "Time_End": 1488.7,
      "Text": " So we like incrementally, like we like a big nice foundation and then we'll build up."
    },
    {
      "Time_Start": 1488.7,
      "Time_End": 1492.8999999999999,
      "Text": " And I would say scientists and a lot of the evaluators in the space are sort of modeled"
    },
    {
      "Time_Start": 1492.8999999999999,
      "Time_End": 1493.8999999999999,
      "Text": " down."
    },
    {
      "Time_Start": 1494.26,
      "Time_End": 1497.94,
      "Text": " So we're coming from that more academic side, that more observability side where it's like"
    },
    {
      "Time_Start": 1497.94,
      "Time_End": 1501.5,
      "Text": " sort of about observing the raw capabilities of the model."
    },
    {
      "Time_Start": 1501.5,
      "Time_End": 1505.0600000000002,
      "Text": " And so what you'll see is, yeah, choose your own path to world domination and let's see"
    },
    {
      "Time_Start": 1505.0600000000002,
      "Time_End": 1507.1000000000001,
      "Text": " if you can do it."
    },
    {
      "Time_Start": 1507.1000000000001,
      "Time_End": 1508.8600000000001,
      "Text": " Build a plan for this thing, right?"
    },
    {
      "Time_Start": 1508.8600000000001,
      "Time_End": 1512.5800000000002,
      "Text": " Like we're not going to tell you what to do versus operators I think which are like, hey,"
    },
    {
      "Time_Start": 1512.5800000000002,
      "Time_End": 1514.3400000000001,
      "Text": " I know what I want to do."
    },
    {
      "Time_Start": 1514.3400000000001,
      "Time_End": 1518.26,
      "Text": " I just need to orchestrate it in the right way."
    },
    {
      "Time_Start": 1518.26,
      "Time_End": 1521.38,
      "Text": " And then I think the key point here is just like we're all evaluators."
    },
    {
      "Time_Start": 1521.38,
      "Time_End": 1526.9,
      "Text": " So if you're using LLMs for whatever task, like if you're not tracking your prompts,"
    },
    {
      "Time_Start": 1526.9,
      "Time_End": 1531.3000000000002,
      "Text": " so it's so easy to just get into a Jupyter Notebook, get into whatever, run a prompt,"
    },
    {
      "Time_Start": 1531.3000000000002,
      "Time_End": 1536.5800000000002,
      "Text": " it doesn't work, type something else, run a prompt, and then 42 hours, three hours later"
    },
    {
      "Time_Start": 1536.5800000000002,
      "Time_End": 1541.38,
      "Text": " you have 60 prompts, 70, 100 prompts that you've done and you've tracked none of it."
    },
    {
      "Time_Start": 1541.38,
      "Time_End": 1546.42,
      "Text": " So you have actually no idea how you've improved or not improved and it's all sort of in your"
    },
    {
      "Time_Start": 1546.42,
      "Time_End": 1547.74,
      "Text": " head anecdotally."
    },
    {
      "Time_Start": 1547.74,
      "Time_End": 1550.3400000000001,
      "Text": " But that's not sort of how LLMs work."
    },
    {
      "Time_Start": 1551.3000000000002,
      "Time_End": 1553.9,
      "Text": " So you want to make sure that you're tracking your prompts."
    },
    {
      "Time_Start": 1553.9,
      "Time_End": 1557.1000000000001,
      "Text": " And it doesn't matter if you have metrics right now, but you're definitely tracking"
    },
    {
      "Time_Start": 1557.1000000000001,
      "Time_End": 1561.0200000000002,
      "Text": " the ins and the outs so you can go back and say, okay, this worked really well, this didn't"
    },
    {
      "Time_Start": 1561.0200000000002,
      "Time_End": 1562.2200000000003,
      "Text": " work really well."
    },
    {
      "Time_Start": 1562.2200000000003,
      "Time_End": 1566.8600000000001,
      "Text": " Because what's happening underneath you are the models are being retrained and changing."
    },
    {
      "Time_Start": 1566.8600000000001,
      "Time_End": 1570.94,
      "Text": " Or if you want to take those same prompts and use them against a different model."
    },
    {
      "Time_Start": 1570.94,
      "Time_End": 1575.5800000000002,
      "Text": " Or at some point in the future when you can no longer use big foundation models for these"
    },
    {
      "Time_Start": 1575.58,
      "Time_End": 1582.4199999999998,
      "Text": " things because, you know, when Azure sort of realized people were using for C2, whatever,"
    },
    {
      "Time_Start": 1582.4199999999998,
      "Time_End": 1587.22,
      "Text": " they came in and started booting people off of tenants, a similar thing might end up happening"
    },
    {
      "Time_Start": 1587.22,
      "Time_End": 1588.22,
      "Text": " for models."
    },
    {
      "Time_Start": 1588.22,
      "Time_End": 1592.46,
      "Text": " So understanding sort of the process of data science and process of these models, yeah,"
    },
    {
      "Time_Start": 1592.46,
      "Time_End": 1597.34,
      "Text": " maybe you won't support like a big foundation model, but as we go forward in time, like"
    },
    {
      "Time_Start": 1597.34,
      "Time_End": 1601.06,
      "Text": " even these 7 billion parameter models are getting really, really good."
    },
    {
      "Time_Start": 1601.06,
      "Time_End": 1606.3,
      "Text": " Or you can even now do, you know, like the mixture 8 by 7 mixture of experts model."
    },
    {
      "Time_Start": 1606.3,
      "Time_End": 1609.26,
      "Text": " Like you can run that at home."
    },
    {
      "Time_Start": 1609.26,
      "Time_End": 1613.82,
      "Text": " Or on vast AI, or there's a couple of different services."
    },
    {
      "Time_Start": 1613.82,
      "Time_End": 1616.34,
      "Text": " But it's important that you just track those."
    },
    {
      "Time_Start": 1622.78,
      "Time_End": 1624.34,
      "Text": " Okay."
    },
    {
      "Time_Start": 1624.34,
      "Time_End": 1626.54,
      "Text": " So we all know what AI might be capable of."
    },
    {
      "Time_Start": 1626.54,
      "Time_End": 1628.3,
      "Text": " We're kind of interested in what it is capable of."
    },
    {
      "Time_Start": 1628.3,
      "Time_End": 1631.8999999999999,
      "Text": " And I would say that's, you know, that's primarily been the crux of my research and"
    },
    {
      "Time_Start": 1631.8999999999999,
      "Time_End": 1635.5,
      "Text": " my work for the longest time."
    },
    {
      "Time_Start": 1635.5,
      "Time_End": 1640.6599999999999,
      "Text": " And I think, you know, the proportion of work performed by ML AI is never going to be zero."
    },
    {
      "Time_Start": 1640.6599999999999,
      "Time_End": 1646.46,
      "Text": " So from here on out, it's really just how much of it is going to be performed by AI."
    },
    {
      "Time_Start": 1646.46,
      "Time_End": 1650.54,
      "Text": " And that's kind of, you know, that's every day I wake up and figure out, you know, what"
    },
    {
      "Time_Start": 1650.54,
      "Time_End": 1652.4199999999998,
      "Text": " more I can push to an LLM."
    },
    {
      "Time_Start": 1652.4199999999998,
      "Time_End": 1653.4199999999998,
      "Text": " Okay."
    },
    {
      "Time_Start": 1653.4199999999998,
      "Time_End": 1656.18,
      "Text": " So here we have a demo."
    },
    {
      "Time_Start": 1656.18,
      "Time_End": 1657.7,
      "Text": " So we just have these tasks."
    },
    {
      "Time_Start": 1658.1000000000001,
      "Time_End": 1659.1000000000001,
      "Text": " So this is our flow."
    },
    {
      "Time_Start": 1659.1000000000001,
      "Time_End": 1663.98,
      "Text": " So we're just going to get all users, decide if it's exploitable, sleep because this is"
    },
    {
      "Time_Start": 1663.98,
      "Time_End": 1666.26,
      "Text": " an API, don't want to get banned."
    },
    {
      "Time_Start": 1666.26,
      "Time_End": 1668.66,
      "Text": " And then we go into, is this exploitable?"
    },
    {
      "Time_Start": 1668.66,
      "Time_End": 1690.42,
      "Text": " And so here we have it, you know, this is just a DAG framework."
    },
    {
      "Time_Start": 1690.42,
      "Time_End": 1697.5400000000002,
      "Text": " So we have all our tasks set up and it's just going through and the LLM underneath is deciding"
    },
    {
      "Time_Start": 1697.5400000000002,
      "Time_End": 1698.5400000000002,
      "Text": " all of these things."
    },
    {
      "Time_Start": 1699.42,
      "Time_End": 1700.42,
      "Text": " So is it exploitable?"
    },
    {
      "Time_Start": 1700.42,
      "Time_End": 1701.42,
      "Text": " Yes or no."
    },
    {
      "Time_Start": 1701.42,
      "Time_End": 1705.18,
      "Text": " And if yes, we push it to a different task."
    },
    {
      "Time_Start": 1705.18,
      "Time_End": 1708.3,
      "Text": " Which is exploitable relationship."
    },
    {
      "Time_Start": 1708.3,
      "Time_End": 1714.26,
      "Text": " And then where it goes off and generates a command for us."
    },
    {
      "Time_Start": 1714.26,
      "Time_End": 1718.86,
      "Text": " And then because it's exploitable, because it's in a state that we it got to that we"
    },
    {
      "Time_Start": 1718.86,
      "Time_End": 1722.54,
      "Text": " like, we're going to save it off as a good example for a dataset."
    },
    {
      "Time_Start": 1722.54,
      "Time_End": 1726.62,
      "Text": " And so when you do this hundreds or thousands of times, you end up creating a massive dataset"
    },
    {
      "Time_Start": 1726.7,
      "Time_End": 1728.9,
      "Text": " that you can then go train on."
    },
    {
      "Time_Start": 1728.9,
      "Time_End": 1734.5400000000002,
      "Text": " And so when you're doing this at scale, those evaluations and those metrics become extremely"
    },
    {
      "Time_Start": 1734.5400000000002,
      "Time_End": 1735.7,
      "Text": " important."
    },
    {
      "Time_Start": 1735.7,
      "Time_End": 1743.18,
      "Text": " Because what ends up happening is, and this is why, you know, you have sort of that whole"
    },
    {
      "Time_Start": 1743.18,
      "Time_End": 1748.8600000000001,
      "Text": " like labeling, data labeling sub-industry that you see."
    },
    {
      "Time_Start": 1748.8600000000001,
      "Time_End": 1749.8600000000001,
      "Text": " These are early on."
    },
    {
      "Time_Start": 1749.8600000000001,
      "Time_End": 1754.8600000000001,
      "Text": " So these are all going to be like exploitable relationships because it's going through."
    },
    {
      "Time_Start": 1754.8600000000001,
      "Time_End": 1755.8600000000001,
      "Text": " But you could do this."
    },
    {
      "Time_Start": 1756.1000000000001,
      "Time_End": 1761.22,
      "Text": " So this is, you know, if you see any sort of like this mapped task, we sort of schedule"
    },
    {
      "Time_Start": 1761.22,
      "Time_End": 1762.22,
      "Text": " these tasks out."
    },
    {
      "Time_Start": 1762.22,
      "Time_End": 1766.38,
      "Text": " But you could do all of the users at the same time if you wanted to."
    },
    {
      "Time_Start": 1766.38,
      "Time_End": 1772.66,
      "Text": " But effectively we go on and sort of here's the command."
    },
    {
      "Time_Start": 1772.66,
      "Time_End": 1777.94,
      "Text": " And we have no idea if this is a good or a bad command."
    },
    {
      "Time_Start": 1777.94,
      "Time_End": 1781.22,
      "Text": " You know, there's sort of that piece where you're like, you still need maybe that human"
    },
    {
      "Time_Start": 1781.22,
      "Time_End": 1782.22,
      "Text": " in the loop."
    },
    {
      "Time_Start": 1782.22,
      "Time_End": 1786.02,
      "Text": " Or you need to go through and construct a different task that would be like validate"
    },
    {
      "Time_Start": 1786.02,
      "Time_End": 1787.02,
      "Text": " that this is accurate."
    },
    {
      "Time_Start": 1787.02,
      "Time_End": 1791.74,
      "Text": " And I think, you know, as a function of not being in networks anymore, we have to build"
    },
    {
      "Time_Start": 1791.74,
      "Time_End": 1792.74,
      "Text": " our own environments."
    },
    {
      "Time_Start": 1792.74,
      "Time_End": 1795.54,
      "Text": " So it's hard to argue with code execution, right?"
    },
    {
      "Time_Start": 1795.54,
      "Time_End": 1801.46,
      "Text": " Like it's when you effectively, you know, get it in an environment versus having to"
    },
    {
      "Time_Start": 1801.46,
      "Time_End": 1803.98,
      "Text": " sort of string match and do those things."
    },
    {
      "Time_Start": 1803.98,
      "Time_End": 1808.54,
      "Text": " Yeah, I guess I'll add to that because this is like something that we've started breaking"
    },
    {
      "Time_Start": 1808.54,
      "Time_End": 1813.06,
      "Text": " down is there are lots of different ways that you can validate the outputs of models."
    },
    {
      "Time_Start": 1813.06,
      "Time_End": 1818.46,
      "Text": " And they range from like sort of validating the characteristics of the output in a more"
    },
    {
      "Time_Start": 1818.46,
      "Time_End": 1819.46,
      "Text": " static way."
    },
    {
      "Time_Start": 1819.46,
      "Time_End": 1823.34,
      "Text": " So yeah, you might do like regex extraction, static string matching."
    },
    {
      "Time_Start": 1823.34,
      "Time_End": 1825.54,
      "Text": " There's like cosine similarities."
    },
    {
      "Time_Start": 1825.54,
      "Time_End": 1829.8999999999999,
      "Text": " You're maybe doing referential where I have a reference list of commands that I know are"
    },
    {
      "Time_Start": 1829.8999999999999,
      "Time_End": 1830.8999999999999,
      "Text": " good."
    },
    {
      "Time_Start": 1830.8999999999999,
      "Time_End": 1833.7,
      "Text": " When you produce commands, I'm just checking to see how well they line up with it."
    },
    {
      "Time_Start": 1833.7,
      "Time_End": 1837.3,
      "Text": " And then there's kind of what I would call like real world validation, which is like"
    },
    {
      "Time_Start": 1837.3,
      "Time_End": 1838.46,
      "Text": " the model has given me a command."
    },
    {
      "Time_Start": 1838.46,
      "Time_End": 1840.02,
      "Text": " I'm going to go put it into an environment."
    },
    {
      "Time_Start": 1840.02,
      "Time_End": 1843.34,
      "Text": " And I'm effectively going to let the environment or the effects of the environment tell me"
    },
    {
      "Time_Start": 1843.34,
      "Time_End": 1845.78,
      "Text": " whether or not the model got the thing correct."
    },
    {
      "Time_Start": 1845.78,
      "Time_End": 1850.58,
      "Text": " And when you talk to the big labs or the governments, they're only ever focused on the latter."
    },
    {
      "Time_Start": 1850.58,
      "Time_End": 1853.62,
      "Text": " That's the only thing they want from these models is like, we're going to go plug it"
    },
    {
      "Time_Start": 1853.62,
      "Time_End": 1854.62,
      "Text": " into a shell."
    },
    {
      "Time_Start": 1854.62,
      "Time_End": 1857.3,
      "Text": " And then it's going to run bash commands to try to hack a CTF."
    },
    {
      "Time_Start": 1857.3,
      "Time_End": 1859.7,
      "Text": " But it's like, that's a really big step for a model."
    },
    {
      "Time_Start": 1859.7,
      "Time_End": 1863.32,
      "Text": " And not only that, but setting up the environment to measure that is very complex."
    },
    {
      "Time_Start": 1863.32,
      "Time_End": 1866.8999999999999,
      "Text": " So there's a lot of intermediate steps before you arrive at that point."
    },
    {
      "Time_Start": 1867.5,
      "Time_End": 1872.94,
      "Text": " And I think people really downplayed the utility that those prior steps can have on ensuring"
    },
    {
      "Time_Start": 1872.94,
      "Time_End": 1875.6200000000001,
      "Text": " that the output is generally aligning with what a human would like."
    },
    {
      "Time_Start": 1875.6200000000001,
      "Time_End": 1880.46,
      "Text": " So when we do these sorts of evaluations, typically we'll produce a bunch of metrics."
    },
    {
      "Time_Start": 1880.46,
      "Time_End": 1884.3000000000002,
      "Text": " And then inside of our framework, we have the ability to like weight those metrics and"
    },
    {
      "Time_Start": 1884.3000000000002,
      "Time_End": 1886.02,
      "Text": " normalize them across each other."
    },
    {
      "Time_Start": 1886.02,
      "Time_End": 1887.02,
      "Text": " So we'll do a bunch of runs."
    },
    {
      "Time_Start": 1887.02,
      "Time_End": 1888.98,
      "Text": " And then we effectively look at a sorted list of outputs."
    },
    {
      "Time_Start": 1888.98,
      "Time_End": 1894.0600000000002,
      "Text": " And as a human, I just start to adjust the metrics until the metrics reflect the best"
    },
    {
      "Time_Start": 1894.0600000000002,
      "Time_End": 1895.0600000000002,
      "Text": " results on the top."
    },
    {
      "Time_Start": 1895.22,
      "Time_End": 1899.3,
      "Text": " It's like, I build the metrics first and then weight them and sort of subtly adjust them,"
    },
    {
      "Time_Start": 1899.3,
      "Time_End": 1901.98,
      "Text": " even though they are like static string representations."
    },
    {
      "Time_Start": 1901.98,
      "Time_End": 1904.82,
      "Text": " You know, for the exploit, it might be like, did you call the binary correctly?"
    },
    {
      "Time_Start": 1904.82,
      "Time_End": 1905.82,
      "Text": " Did you avoid XML?"
    },
    {
      "Time_Start": 1905.82,
      "Time_End": 1907.48,
      "Text": " Did you avoid C-sharp code?"
    },
    {
      "Time_Start": 1907.48,
      "Time_End": 1909.8999999999999,
      "Text": " Did you go try to use Netcat?"
    },
    {
      "Time_Start": 1909.8999999999999,
      "Time_End": 1911.58,
      "Text": " Like I might weight all of those differently."
    },
    {
      "Time_Start": 1911.58,
      "Time_End": 1915.06,
      "Text": " And I generally just want to align those to what I'd like to see out of the model."
    },
    {
      "Time_Start": 1915.06,
      "Time_End": 1917.06,
      "Text": " Sorry, I just wanted to add that."
    },
    {
      "Time_Start": 1919.06,
      "Time_End": 1921.74,
      "Text": " And then because it's a DAG, it doesn't really matter."
    },
    {
      "Time_Start": 1921.74,
      "Time_End": 1922.74,
      "Text": " You can do any task."
    },
    {
      "Time_Start": 1922.74,
      "Time_End": 1926.18,
      "Text": " So we have the silica, which is dnspy."
    },
    {
      "Time_Start": 1926.18,
      "Time_End": 1927.18,
      "Text": " And we orchestrate that."
    },
    {
      "Time_Start": 1927.18,
      "Time_End": 1929.54,
      "Text": " We have like a basic mythic one."
    },
    {
      "Time_Start": 1929.54,
      "Time_End": 1931.26,
      "Text": " We have a basic burp one."
    },
    {
      "Time_Start": 1931.26,
      "Time_End": 1936.58,
      "Text": " But yeah, I guess it being a sort of a conference on graphs, you know, we kind of, we're used"
    },
    {
      "Time_Start": 1936.58,
      "Time_End": 1941.06,
      "Text": " to thinking of graphs as this like static piece of information that we go search through."
    },
    {
      "Time_Start": 1941.06,
      "Time_End": 1945.38,
      "Text": " But instead, if you think of every node as sort of a task or a function, it kind of makes"
    },
    {
      "Time_Start": 1945.38,
      "Time_End": 1948.22,
      "Text": " a little more dynamic and, you know, that whole orchestration."
    },
    {
      "Time_Start": 1948.22,
      "Time_End": 1955.82,
      "Text": " So as an operator, you know, we kind of think, you know, on the path to Skynet, there's a"
    },
    {
      "Time_Start": 1955.82,
      "Time_End": 1960.38,
      "Text": " lot of baby steps and, you know, this task orchestration is sort of one of them."
    },
    {
      "Time_Start": 1960.38,
      "Time_End": 1964.18,
      "Text": " And then at the end, you know, we have, we'll have this big data set that we can do."
    },
    {
      "Time_Start": 1964.18,
      "Time_End": 1969.78,
      "Text": " And we kind of use tasks as like, if it gets to an exploitable relationship point, like"
    },
    {
      "Time_Start": 1969.78,
      "Time_End": 1971.98,
      "Text": " that means something important."
    },
    {
      "Time_Start": 1971.98,
      "Time_End": 1975.02,
      "Text": " And so we can look here, we have like five, this has been ran five times."
    },
    {
      "Time_Start": 1975.02,
      "Time_End": 1979.94,
      "Text": " So there's like five exploitable relationships, whatever that means."
    },
    {
      "Time_Start": 1979.94,
      "Time_End": 1983.86,
      "Text": " You know, and these are all going to be sort of the domain admins because at the beginning"
    },
    {
      "Time_Start": 1983.86,
      "Time_End": 1988.06,
      "Text": " for this particular environment, there's 18 of them that it pulls out."
    },
    {
      "Time_Start": 1988.06,
      "Time_End": 1992.5,
      "Text": " And then, you know, with an environment, because we have tools like Bloodhound, you can take"
    },
    {
      "Time_Start": 1992.5,
      "Time_End": 1997.18,
      "Text": " this, go compare your results, and then sort of see how the model does against like a very"
    },
    {
      "Time_Start": 1997.18,
      "Time_End": 1998.78,
      "Text": " static sort of environment."
    },
    {
      "Time_Start": 2006.02,
      "Time_End": 2007.02,
      "Text": " Cool."
    },
    {
      "Time_Start": 2007.02,
      "Time_End": 2012.34,
      "Text": " Yeah, I think actually, I'll finish on Will's point about like, you know, we're in the offense"
    },
    {
      "Time_Start": 2012.34,
      "Time_End": 2015.62,
      "Text": " space in particular, like, we're going to have to get used to working with limited information,"
    },
    {
      "Time_Start": 2015.62,
      "Time_End": 2016.62,
      "Text": " right?"
    },
    {
      "Time_Start": 2016.62,
      "Time_End": 2019.74,
      "Text": " Like, if there's one thing that's going to get stripped first, it's your ability to pull"
    },
    {
      "Time_Start": 2019.74,
      "Time_End": 2023.22,
      "Text": " excessive information about an environment for decision making processes."
    },
    {
      "Time_Start": 2023.22,
      "Time_End": 2027.82,
      "Text": " I think, you know, a lot of people might argue that the static analysis of that information"
    },
    {
      "Time_Start": 2027.82,
      "Time_End": 2032.02,
      "Text": " is obviously going to blow any dynamic analysis, it's like model backed out of the water."
    },
    {
      "Time_Start": 2032.02,
      "Time_End": 2036.06,
      "Text": " But the reality is like that static analysis depends on full information, whereas like"
    },
    {
      "Time_Start": 2036.06,
      "Time_End": 2037.9,
      "Text": " these models can infer relationships."
    },
    {
      "Time_Start": 2037.9,
      "Time_End": 2041.22,
      "Text": " So like, the idea is you might only be working with partial information, and this could very"
    },
    {
      "Time_Start": 2041.22,
      "Time_End": 2045.3,
      "Text": " well be what we do identity analysis with in the future from partial info scenarios"
    },
    {
      "Time_Start": 2045.3,
      "Time_End": 2049.1,
      "Text": " is like, the model is looking at a set of partial information and coming up with intuitions"
    },
    {
      "Time_Start": 2049.1,
      "Time_End": 2052.86,
      "Text": " about what relationships may or may not exist with particular confidence levels."
    },
    {
      "Time_Start": 2052.86,
      "Time_End": 2054.94,
      "Text": " So yeah, we're going to pivot now."
    },
    {
      "Time_Start": 2054.94,
      "Time_End": 2056.1,
      "Text": " It's a bit of a harsh pivot."
    },
    {
      "Time_Start": 2056.1,
      "Time_End": 2059.42,
      "Text": " But you know, I think it would be improper for us to leave this conference without chatting"
    },
    {
      "Time_Start": 2059.42,
      "Time_End": 2060.9,
      "Text": " a little bit about adversarial ML."
    },
    {
      "Time_Start": 2060.9,
      "Time_End": 2065.38,
      "Text": " The way we think about the spaces inside of models, up until now, we've been very much"
    },
    {
      "Time_Start": 2065.38,
      "Time_End": 2066.38,
      "Text": " on the engineering side."
    },
    {
      "Time_Start": 2066.38,
      "Time_End": 2070.7000000000003,
      "Text": " So we've been talking about like using these models in orchestration and tasks of the realities"
    },
    {
      "Time_Start": 2070.7000000000003,
      "Time_End": 2073.02,
      "Text": " of the models themselves are really fascinating."
    },
    {
      "Time_Start": 2073.02,
      "Time_End": 2076.1800000000003,
      "Text": " And this is a technology that attackers will be forced to understand."
    },
    {
      "Time_Start": 2076.1800000000003,
      "Time_End": 2081.62,
      "Text": " When Will and I started this company, we effectively committed the idea that we would be a company"
    },
    {
      "Time_Start": 2081.62,
      "Time_End": 2086.06,
      "Text": " in the small subgroup and growing subgroup of like AI security experts, which is really"
    },
    {
      "Time_Start": 2086.06,
      "Time_End": 2088.78,
      "Text": " no different than cloud security experts, right?"
    },
    {
      "Time_Start": 2088.78,
      "Time_End": 2092.2200000000003,
      "Text": " Because like cloud security experts didn't used to exist, it was just cloud engineers"
    },
    {
      "Time_Start": 2092.2200000000003,
      "Time_End": 2093.2200000000003,
      "Text": " and security experts."
    },
    {
      "Time_Start": 2093.2200000000003,
      "Time_End": 2096.9,
      "Text": " And then over time, those two disciplines created a new subspace where you can specialize"
    },
    {
      "Time_Start": 2096.9,
      "Time_End": 2097.9,
      "Text": " solely on cloud."
    },
    {
      "Time_Start": 2097.9,
      "Time_End": 2099.6600000000003,
      "Text": " And AI is the same way."
    },
    {
      "Time_Start": 2099.6600000000003,
      "Time_End": 2104.5400000000004,
      "Text": " So the way I want to introduce thinking about these models is that like a model represents"
    },
    {
      "Time_Start": 2104.5400000000004,
      "Time_End": 2106.5800000000004,
      "Text": " a parameter space inside of it."
    },
    {
      "Time_Start": 2106.5800000000004,
      "Time_End": 2109.78,
      "Text": " And as attackers, we're most interested in navigating that parameter space as efficiently"
    },
    {
      "Time_Start": 2109.78,
      "Time_End": 2110.82,
      "Text": " as possible."
    },
    {
      "Time_Start": 2110.82,
      "Time_End": 2115.46,
      "Text": " We define useful points inside of that space as points that yield a particular output for"
    },
    {
      "Time_Start": 2115.46,
      "Time_End": 2117.5,
      "Text": " a given input."
    },
    {
      "Time_Start": 2117.5,
      "Time_End": 2121.38,
      "Text": " Typically we're looking for like misclassification or arbitrary control over say the output logits"
    },
    {
      "Time_Start": 2121.38,
      "Time_End": 2123.62,
      "Text": " of a model given input logits."
    },
    {
      "Time_Start": 2123.62,
      "Time_End": 2126.62,
      "Text": " And our goal is to explore that parameter space while minimizing the number of queries"
    },
    {
      "Time_Start": 2126.62,
      "Time_End": 2129.58,
      "Text": " and optimizing for whatever constraints we want, which is different than the academic"
    },
    {
      "Time_Start": 2129.58,
      "Time_End": 2130.58,
      "Text": " research, right?"
    },
    {
      "Time_Start": 2130.58,
      "Time_End": 2134.18,
      "Text": " Like Will brought up that idea that, you know, the standard academic research is I want the"
    },
    {
      "Time_Start": 2134.18,
      "Time_End": 2135.3,
      "Text": " lowest number."
    },
    {
      "Time_Start": 2135.3,
      "Time_End": 2139.06,
      "Text": " So I'm literally going to throw as many queries at it as possible until I get the lowest number"
    },
    {
      "Time_Start": 2139.06,
      "Time_End": 2141.62,
      "Text": " because that means I win and I get to write a paper."
    },
    {
      "Time_Start": 2141.62,
      "Time_End": 2143.16,
      "Text": " As attackers, that's not what that means for us."
    },
    {
      "Time_Start": 2143.16,
      "Time_End": 2147.18,
      "Text": " We actually have constraints and goals that we're trying to meet within, you know, boundaries."
    },
    {
      "Time_Start": 2147.18,
      "Time_End": 2150.8599999999997,
      "Text": " Like we don't want to just abuse the number of queries we call."
    },
    {
      "Time_Start": 2150.8599999999997,
      "Time_End": 2152.72,
      "Text": " This is like an example of a really basic attack."
    },
    {
      "Time_Start": 2152.72,
      "Time_End": 2155.14,
      "Text": " So this code should be fairly understandable."
    },
    {
      "Time_Start": 2155.14,
      "Time_End": 2158.8599999999997,
      "Text": " It's effectively this idea that you have a tensor of information."
    },
    {
      "Time_Start": 2158.8599999999997,
      "Time_End": 2164.18,
      "Text": " And this is also another component, an element of this AI security subspace, which is web"
    },
    {
      "Time_Start": 2164.18,
      "Time_End": 2169.2999999999997,
      "Text": " app security, app sec professionals think in the protocol of HTTP most frequently, right?"
    },
    {
      "Time_Start": 2169.2999999999997,
      "Time_End": 2172.8599999999997,
      "Text": " Like everything about their tooling and their process is designed around the fundamental"
    },
    {
      "Time_Start": 2172.8599999999997,
      "Time_End": 2176.7799999999997,
      "Text": " protocol that backs that relationship between a client and a server."
    },
    {
      "Time_Start": 2176.78,
      "Time_End": 2181.1400000000003,
      "Text": " AI security experts will exist in the protocol of tensors."
    },
    {
      "Time_Start": 2181.1400000000003,
      "Time_End": 2184.78,
      "Text": " Tensors are just numerical data that represents any other data."
    },
    {
      "Time_Start": 2184.78,
      "Time_End": 2186.1000000000004,
      "Text": " And they can represent any feature."
    },
    {
      "Time_Start": 2186.1000000000004,
      "Time_End": 2190.1800000000003,
      "Text": " Will has this great quote where he says that you could effectively describe every possible"
    },
    {
      "Time_Start": 2190.1800000000003,
      "Time_End": 2192.1400000000003,
      "Text": " tree in the world using pure distributions."
    },
    {
      "Time_Start": 2192.1400000000003,
      "Time_End": 2197.0600000000004,
      "Text": " Like you can describe anything in the world by just quantifying it in some way."
    },
    {
      "Time_Start": 2197.0600000000004,
      "Time_End": 2198.9,
      "Text": " And tensors can represent everything."
    },
    {
      "Time_Start": 2198.9,
      "Time_End": 2199.9,
      "Text": " Tensors can represent images."
    },
    {
      "Time_Start": 2199.9,
      "Time_End": 2200.9,
      "Text": " They can represent text."
    },
    {
      "Time_Start": 2200.9,
      "Time_End": 2201.9,
      "Text": " They can represent audio."
    },
    {
      "Time_Start": 2201.9,
      "Time_End": 2202.9,
      "Text": " It doesn't matter."
    },
    {
      "Time_Start": 2202.9,
      "Time_End": 2203.9,
      "Text": " They don't care what they're representing."
    },
    {
      "Time_Start": 2204.3,
      "Time_End": 2207.1,
      "Text": " This is a very tough protocol to operate on, but it's really fascinating."
    },
    {
      "Time_Start": 2207.1,
      "Time_End": 2211.02,
      "Text": " And it offers like very cool intuitions about what it means to navigate that latent space"
    },
    {
      "Time_Start": 2211.02,
      "Time_End": 2212.02,
      "Text": " in a model."
    },
    {
      "Time_Start": 2212.02,
      "Time_End": 2216.26,
      "Text": " So yeah, in this case, we're effectively, we have a feedback mechanism where we're asking"
    },
    {
      "Time_Start": 2216.26,
      "Time_End": 2217.86,
      "Text": " a model to score an input."
    },
    {
      "Time_Start": 2217.86,
      "Time_End": 2220.6600000000003,
      "Text": " And we effectively perturb that input in a bunch of different directions."
    },
    {
      "Time_Start": 2220.6600000000003,
      "Time_End": 2224.56,
      "Text": " We take the next input, the next best input that produces the next best score."
    },
    {
      "Time_Start": 2224.56,
      "Time_End": 2225.56,
      "Text": " And we work from there."
    },
    {
      "Time_Start": 2225.56,
      "Time_End": 2227.1800000000003,
      "Text": " This is like the most simple example."
    },
    {
      "Time_Start": 2227.1800000000003,
      "Time_End": 2229.86,
      "Text": " A more advanced example would be something like HopSkipJump."
    },
    {
      "Time_Start": 2229.86,
      "Time_End": 2233.5,
      "Text": " In our library, we rethink the concept of these generators a little bit."
    },
    {
      "Time_Start": 2233.5,
      "Time_End": 2236.86,
      "Text": " So in the academic world, HopSkipJump is a process where you set up a bunch of dominoes"
    },
    {
      "Time_Start": 2236.86,
      "Time_End": 2239.34,
      "Text": " and you tip it over and you wait for it to finish."
    },
    {
      "Time_Start": 2239.34,
      "Time_End": 2243.42,
      "Text": " In our realm, we think of HopSkipJump or all of these algorithms as being infinite generators."
    },
    {
      "Time_Start": 2243.42,
      "Time_End": 2248.08,
      "Text": " Their job is to consistently, given a set of priors, produce the next best input."
    },
    {
      "Time_Start": 2248.08,
      "Time_End": 2251.38,
      "Text": " We can test that input and then decide whether or not we want to have the algorithm run again"
    },
    {
      "Time_Start": 2251.38,
      "Time_End": 2253.06,
      "Text": " and give us the next best input."
    },
    {
      "Time_Start": 2253.06,
      "Time_End": 2256.1,
      "Text": " So we design these algorithms using a lot of Python generators where we can do nested"
    },
    {
      "Time_Start": 2256.1,
      "Time_End": 2257.1,
      "Text": " yield froms."
    },
    {
      "Time_Start": 2257.1,
      "Time_End": 2260.82,
      "Text": " We effectively have this code ask continuously for fresh inputs."
    },
    {
      "Time_Start": 2260.82,
      "Time_End": 2268.34,
      "Text": " It can delegate out to other functions or algorithms, like bisection blend is a..."
    },
    {
      "Time_Start": 2268.34,
      "Time_End": 2269.34,
      "Text": " What's the other term for that?"
    },
    {
      "Time_Start": 2269.34,
      "Time_End": 2270.34,
      "Text": " I call it bisection blend."
    },
    {
      "Time_Start": 2270.34,
      "Time_End": 2271.34,
      "Text": " That's a poor term."
    },
    {
      "Time_Start": 2271.34,
      "Time_End": 2272.34,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2272.34,
      "Time_End": 2273.34,
      "Text": " Binary search."
    },
    {
      "Time_Start": 2273.34,
      "Time_End": 2274.34,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2274.34,
      "Time_End": 2276.6600000000003,
      "Text": " Bisection blend is like binary search, where effectively you have a threshold data that"
    },
    {
      "Time_Start": 2276.6600000000003,
      "Time_End": 2278.1200000000003,
      "Text": " you're trying to stay within."
    },
    {
      "Time_Start": 2278.1200000000003,
      "Time_End": 2281.9,
      "Text": " You effectively take two input samples and you continuously blend between them."
    },
    {
      "Time_Start": 2281.9,
      "Time_End": 2286.82,
      "Text": " And you effectively find the point in space where your classification label changes."
    },
    {
      "Time_Start": 2286.82,
      "Time_End": 2288.6600000000003,
      "Text": " And you find the narrowest point there."
    },
    {
      "Time_Start": 2288.6600000000003,
      "Time_End": 2290.2200000000003,
      "Text": " That's a fundamental part of HopSkipJump."
    },
    {
      "Time_Start": 2290.2200000000003,
      "Time_End": 2293.26,
      "Text": " But the bisection blend, it's on its own, is its own algorithm."
    },
    {
      "Time_Start": 2293.26,
      "Time_End": 2298.1600000000003,
      "Text": " It produces a set of inputs based on priors and continuously produces those inputs until"
    },
    {
      "Time_Start": 2298.1600000000003,
      "Time_End": 2299.6000000000004,
      "Text": " some threshold is met."
    },
    {
      "Time_Start": 2299.6000000000004,
      "Time_End": 2301.1800000000003,
      "Text": " So we can use that inside of HopSkipJump."
    },
    {
      "Time_Start": 2301.1800000000003,
      "Time_End": 2304.86,
      "Text": " And this is the way that we'll build constructive algorithms in a framework that's more akin"
    },
    {
      "Time_Start": 2304.86,
      "Time_End": 2306.5400000000004,
      "Text": " to something like Burp."
    },
    {
      "Time_Start": 2306.5400000000004,
      "Time_End": 2310.2200000000003,
      "Text": " The adversarial algorithms and their frameworks right now are not designed to do this sort"
    },
    {
      "Time_Start": 2310.2200000000003,
      "Time_End": 2311.2200000000003,
      "Text": " of stuff."
    },
    {
      "Time_Start": 2311.2200000000003,
      "Time_End": 2312.2200000000003,
      "Text": " They're designed to be experimental."
    },
    {
      "Time_Start": 2312.2200000000003,
      "Time_End": 2315.9,
      "Text": " They're designed to validate behaviors and produce metrics."
    },
    {
      "Time_Start": 2315.9,
      "Time_End": 2318.86,
      "Text": " In our case, we want to think of them more like an engineering problem."
    },
    {
      "Time_Start": 2318.86,
      "Time_End": 2323.02,
      "Text": " So this is us getting extremely positive HopSkipJump."
    },
    {
      "Time_Start": 2323.02,
      "Time_End": 2326.1400000000003,
      "Text": " So these two fives in MNIST are labeled the exact same."
    },
    {
      "Time_Start": 2326.1400000000003,
      "Time_End": 2331.46,
      "Text": " And in the standard ART HopSkipJump, it would get a similar success rate with 25,000 queries."
    },
    {
      "Time_Start": 2331.46,
      "Time_End": 2333.02,
      "Text": " We do it with 1,200."
    },
    {
      "Time_Start": 2333.02,
      "Time_End": 2336.54,
      "Text": " So it just shows how much wasted query time they're doing just to get slightly better"
    },
    {
      "Time_Start": 2336.54,
      "Time_End": 2339.5,
      "Text": " performance improvements."
    },
    {
      "Time_Start": 2339.5,
      "Time_End": 2341.82,
      "Text": " All of this is very adversarial ML, if you haven't seen it."
    },
    {
      "Time_Start": 2341.82,
      "Time_End": 2345.9,
      "Text": " It's very fascinating, classifying images of cats as dogs and whatnot."
    },
    {
      "Time_Start": 2345.9,
      "Time_End": 2348.2200000000003,
      "Text": " So yeah, I know we're running out of time."
    },
    {
      "Time_Start": 2348.5800000000004,
      "Time_End": 2352.0200000000004,
      "Text": " I'll chat a little bit about adversarial spaces for language models, because I think it's"
    },
    {
      "Time_Start": 2352.0200000000004,
      "Time_End": 2354.1000000000004,
      "Text": " probably of interest to people."
    },
    {
      "Time_Start": 2354.1000000000004,
      "Time_End": 2356.86,
      "Text": " Essentially, there's a history of..."
    },
    {
      "Time_Start": 2356.86,
      "Time_End": 2360.6200000000003,
      "Text": " I sort of bucket them into three different categories of adversarial attacks for NLP."
    },
    {
      "Time_Start": 2360.6200000000003,
      "Time_End": 2366.0200000000004,
      "Text": " There was early NLP, which was very, I want a model to label this comment in a sentiment."
    },
    {
      "Time_Start": 2366.0200000000004,
      "Time_End": 2367.7000000000003,
      "Text": " Neutral, positive, negative."
    },
    {
      "Time_Start": 2367.7000000000003,
      "Time_End": 2371.9,
      "Text": " This is very immature, old-school models that we used to work with."
    },
    {
      "Time_Start": 2371.9,
      "Time_End": 2372.9,
      "Text": " BERT kind of came out."
    },
    {
      "Time_Start": 2372.9,
      "Time_End": 2375.5800000000004,
      "Text": " People started doing summarization and light QA tasks, and now we're in this totally new"
    },
    {
      "Time_Start": 2375.62,
      "Time_End": 2380.34,
      "Text": " world of broad adoption, where you have causal generation, multimodal inputs."
    },
    {
      "Time_Start": 2380.34,
      "Time_End": 2382.5,
      "Text": " And I've sort of listed out some of the attacks there."
    },
    {
      "Time_Start": 2382.5,
      "Time_End": 2386.46,
      "Text": " More modern attacks that you'll see for LLMs are typically revolved around jailbreaking,"
    },
    {
      "Time_Start": 2386.46,
      "Time_End": 2390.8199999999997,
      "Text": " although Will and I chatted last night, and this is changing a little bit as people realize"
    },
    {
      "Time_Start": 2390.8199999999997,
      "Time_End": 2393.02,
      "Text": " that jailbreaking is not the only..."
    },
    {
      "Time_Start": 2393.02,
      "Time_End": 2396.7,
      "Text": " Arbitrary control over the input logits of a model, to some degree, results in arbitrary"
    },
    {
      "Time_Start": 2396.7,
      "Time_End": 2401.74,
      "Text": " control of the output logits, which themselves can be used for jailbreaking, or prompt injection,"
    },
    {
      "Time_Start": 2401.74,
      "Time_End": 2402.74,
      "Text": " or misclassification."
    },
    {
      "Time_Start": 2402.74,
      "Time_End": 2403.74,
      "Text": " It doesn't matter."
    },
    {
      "Time_Start": 2404.7400000000002,
      "Time_End": 2407.1000000000004,
      "Text": " LLMs are classifiers."
    },
    {
      "Time_Start": 2407.1000000000004,
      "Time_End": 2411.7000000000003,
      "Text": " Most LLMs, or most all models are classifiers, but yeah, they don't generate text, they predict"
    },
    {
      "Time_Start": 2411.7000000000003,
      "Time_End": 2412.7000000000003,
      "Text": " the next token."
    },
    {
      "Time_Start": 2412.7000000000003,
      "Time_End": 2416.46,
      "Text": " They classify for a given set of inputs the next token, so they can be broken in the exact"
    },
    {
      "Time_Start": 2416.46,
      "Time_End": 2417.46,
      "Text": " same way."
    },
    {
      "Time_Start": 2417.46,
      "Time_End": 2421.1000000000004,
      "Text": " So, here's a little background on the very first primitive of these attacks."
    },
    {
      "Time_Start": 2421.1000000000004,
      "Time_End": 2425.0200000000004,
      "Text": " This you can find under LLM attacks, and we have an implementation and a notebook for"
    },
    {
      "Time_Start": 2425.0200000000004,
      "Time_End": 2428.98,
      "Text": " Mistral, but this is called Greedy Coordinate Gradients, or GCG."
    },
    {
      "Time_Start": 2428.98,
      "Time_End": 2433.0200000000004,
      "Text": " The issue with LLMs is, while in the rest of adversarial ML, especially on the images"
    },
    {
      "Time_Start": 2433.02,
      "Time_End": 2437.14,
      "Text": " side, you can do continuous optimization, because the input space is continuous."
    },
    {
      "Time_Start": 2437.14,
      "Time_End": 2440.5,
      "Text": " So changing a pixel slightly in an image doesn't give you an entirely new image."
    },
    {
      "Time_Start": 2440.5,
      "Time_End": 2444.08,
      "Text": " Unfortunately, in the text space, we don't have that freedom."
    },
    {
      "Time_Start": 2444.08,
      "Time_End": 2447.42,
      "Text": " Changing a token of a text can completely change the meaning of a sentence, and because"
    },
    {
      "Time_Start": 2447.42,
      "Time_End": 2450.86,
      "Text": " the tokens are discrete, they're not necessarily naturally related to each other."
    },
    {
      "Time_Start": 2450.86,
      "Time_End": 2456.38,
      "Text": " You can somewhat synthetically produce a gradient by producing a suffix, enabling gradients"
    },
    {
      "Time_Start": 2456.38,
      "Time_End": 2461.82,
      "Text": " on that particular part of the input, pushing it through calculating a loss, back-propping,"
    },
    {
      "Time_Start": 2461.82,
      "Time_End": 2465.82,
      "Text": " and then you effectively get from the embedding token space a set of tokens that are, like,"
    },
    {
      "Time_Start": 2465.82,
      "Time_End": 2471.46,
      "Text": " the most likely tokens to slot into that suffix space for that given loss."
    },
    {
      "Time_Start": 2471.46,
      "Time_End": 2472.6600000000003,
      "Text": " And then the attack is really basic."
    },
    {
      "Time_Start": 2472.6600000000003,
      "Time_End": 2476.54,
      "Text": " It just starts, like, randomly slotting in tokens at random places and running the loss"
    },
    {
      "Time_Start": 2476.54,
      "Time_End": 2477.54,
      "Text": " again and again and again."
    },
    {
      "Time_Start": 2477.54,
      "Time_End": 2481.98,
      "Text": " This is a pretty heavy attack, and like I said, it's analogous to gradients because"
    },
    {
      "Time_Start": 2481.98,
      "Time_End": 2485.42,
      "Text": " they can't really get true gradients, but they are getting gradients all the way back"
    },
    {
      "Time_Start": 2485.42,
      "Time_End": 2487.7000000000003,
      "Text": " to the embedding layers, which is close enough."
    },
    {
      "Time_Start": 2487.7000000000003,
      "Time_End": 2490.9,
      "Text": " It lets them get a list of tokens that are the best candidate."
    },
    {
      "Time_Start": 2490.9,
      "Time_End": 2494.9,
      "Text": " Then there's more modern attacks, like beam search attacks, and actually the beam search"
    },
    {
      "Time_Start": 2494.9,
      "Time_End": 2498.82,
      "Text": " attack and that GCG are blended together in what they call autodan."
    },
    {
      "Time_Start": 2498.82,
      "Time_End": 2500.38,
      "Text": " All of these attacks have unique names."
    },
    {
      "Time_Start": 2500.38,
      "Time_End": 2502.58,
      "Text": " All of the papers have a lot of really complicated math."
    },
    {
      "Time_Start": 2502.58,
      "Time_End": 2503.58,
      "Text": " It's not that complicated."
    },
    {
      "Time_Start": 2503.58,
      "Time_End": 2505.1,
      "Text": " They're all talking about the same stuff."
    },
    {
      "Time_Start": 2505.1,
      "Time_End": 2509.44,
      "Text": " In a beam search attack, they just abuse the traditional way that an LLM generates inputs."
    },
    {
      "Time_Start": 2509.44,
      "Time_End": 2513.88,
      "Text": " For those who have heard of beam searches or n-beams, if you've seen generating an LLM,"
    },
    {
      "Time_Start": 2513.88,
      "Time_End": 2518.38,
      "Text": " it's a causal token selection method where, for any given set of input tokens, you effectively"
    },
    {
      "Time_Start": 2518.38,
      "Time_End": 2522.78,
      "Text": " spray out to a set of output tokens, and you can take that tree step as many times"
    },
    {
      "Time_Start": 2522.78,
      "Time_End": 2523.78,
      "Text": " as you want."
    },
    {
      "Time_Start": 2523.78,
      "Time_End": 2527.44,
      "Text": " You say, I want K number of tokens, and then I'm going to take the next step of tokens"
    },
    {
      "Time_Start": 2527.44,
      "Time_End": 2529.7000000000003,
      "Text": " for each of those K1s."
    },
    {
      "Time_Start": 2529.7000000000003,
      "Time_End": 2535.86,
      "Text": " The beam search attack effectively builds a big set of K1 by K2 pairs, runs them through,"
    },
    {
      "Time_Start": 2535.86,
      "Time_End": 2537.5,
      "Text": " calculates loss on the suffix."
    },
    {
      "Time_Start": 2537.5,
      "Time_End": 2539.84,
      "Text": " You might imagine that they're sitting on an input."
    },
    {
      "Time_Start": 2539.84,
      "Time_End": 2543.6600000000003,
      "Text": " They want an output over here, and in the middle, there's all of these incredibly dense"
    },
    {
      "Time_Start": 2543.6600000000003,
      "Time_End": 2546.6600000000003,
      "Text": " branches of all these token paths that they could take."
    },
    {
      "Time_Start": 2546.66,
      "Time_End": 2551.22,
      "Text": " They're effectively beam searching out and trying to pick the path with the lowest loss."
    },
    {
      "Time_Start": 2551.22,
      "Time_End": 2554.56,
      "Text": " So they're trying to take the next step down this really dense tree so that they eventually"
    },
    {
      "Time_Start": 2554.56,
      "Time_End": 2556.66,
      "Text": " arrive back at the suffix."
    },
    {
      "Time_Start": 2556.66,
      "Time_End": 2559.44,
      "Text": " Nice part about this is they don't have to enable gradients for the models."
    },
    {
      "Time_Start": 2559.44,
      "Time_End": 2561.62,
      "Text": " They can use the logits, which are the outputs of the models."
    },
    {
      "Time_Start": 2561.62,
      "Time_End": 2563.58,
      "Text": " It's a really clean way to do it."
    },
    {
      "Time_Start": 2563.58,
      "Time_End": 2567.5,
      "Text": " And then there's the alternative, which is pair and tap, which we also have an implementation"
    },
    {
      "Time_Start": 2567.5,
      "Time_End": 2573.2999999999997,
      "Text": " of, where it's effectively asking models to produce malicious prompts, scoring them with"
    },
    {
      "Time_Start": 2573.3,
      "Time_End": 2577.94,
      "Text": " other models, targeting a model, and then re-running that process again and again."
    },
    {
      "Time_Start": 2577.94,
      "Time_End": 2579.78,
      "Text": " So this is not mathematical."
    },
    {
      "Time_Start": 2579.78,
      "Time_End": 2583.6600000000003,
      "Text": " This is effectively having models produce, hey, I want a prompt that will get another"
    },
    {
      "Time_Start": 2583.6600000000003,
      "Time_End": 2585.46,
      "Text": " model to tell me how to build a bomb."
    },
    {
      "Time_Start": 2585.46,
      "Time_End": 2586.46,
      "Text": " Make me that prompt."
    },
    {
      "Time_Start": 2586.46,
      "Time_End": 2587.94,
      "Text": " And then you evaluate it."
    },
    {
      "Time_Start": 2587.94,
      "Time_End": 2590.82,
      "Text": " And the tree effectively expands with a branching factor."
    },
    {
      "Time_Start": 2590.82,
      "Time_End": 2593.28,
      "Text": " You do evaluation and pruning at every sub-step."
    },
    {
      "Time_Start": 2593.28,
      "Time_End": 2594.28,
      "Text": " This is super basic."
    },
    {
      "Time_Start": 2594.28,
      "Time_End": 2597.48,
      "Text": " Like, if you go look at our Parlay code, it's super trivial."
    },
    {
      "Time_Start": 2597.48,
      "Time_End": 2599.6600000000003,
      "Text": " It's like 80 lines of Python to get this working."
    },
    {
      "Time_Start": 2599.66,
      "Time_End": 2603.58,
      "Text": " If you go and read the paper, it's like 15 pages of mathematical formulas."
    },
    {
      "Time_Start": 2603.58,
      "Time_End": 2605.06,
      "Text": " Like, they just go overboard with that."
    },
    {
      "Time_Start": 2605.06,
      "Time_End": 2609.98,
      "Text": " And I think it's worth mentioning that these techniques are actually really simple at their"
    },
    {
      "Time_Start": 2609.98,
      "Time_End": 2610.98,
      "Text": " premise."
    },
    {
      "Time_Start": 2610.98,
      "Time_End": 2613.8999999999996,
      "Text": " We have a couple of references here."
    },
    {
      "Time_Start": 2613.8999999999996,
      "Time_End": 2617.44,
      "Text": " We have a big paper stack on our Notion, where we effectively continually pull in papers"
    },
    {
      "Time_Start": 2617.44,
      "Time_End": 2620.42,
      "Text": " about adversarial machine learning and offensive ML."
    },
    {
      "Time_Start": 2620.42,
      "Time_End": 2622.7599999999998,
      "Text": " It updates continuously and builds summaries."
    },
    {
      "Time_Start": 2622.7599999999998,
      "Time_End": 2626.7,
      "Text": " So I recommend, if you want to go play around and look at archive, that's great."
    },
    {
      "Time_Start": 2626.7,
      "Time_End": 2627.7,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2627.7400000000002,
      "Time_End": 2630.3,
      "Text": " Any final references that you would throw out here?"
    },
    {
      "Time_Start": 2630.3,
      "Time_End": 2631.3,
      "Text": " I made this slide not well."
    },
    {
      "Time_Start": 2631.3,
      "Time_End": 2632.3,
      "Text": " So we might have some other thoughts."
    },
    {
      "Time_Start": 2632.3,
      "Time_End": 2633.3,
      "Text": " No."
    },
    {
      "Time_Start": 2633.3,
      "Time_End": 2634.3,
      "Text": " Cool."
    },
    {
      "Time_Start": 2634.3,
      "Time_End": 2635.3,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2635.3,
      "Time_End": 2636.3,
      "Text": " I think that's it."
    },
    {
      "Time_Start": 2636.3,
      "Time_End": 2638.3,
      "Text": " I guess, any final thoughts from you before we take questions?"
    },
    {
      "Time_Start": 2638.3,
      "Time_End": 2639.3,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2639.3,
      "Time_End": 2642.86,
      "Text": " So I think you see a lot of things like, hey, can you build a bomb?"
    },
    {
      "Time_Start": 2642.86,
      "Time_End": 2644.5800000000004,
      "Text": " It doesn't matter."
    },
    {
      "Time_Start": 2644.5800000000004,
      "Time_End": 2645.6200000000003,
      "Text": " You can do whatever you want."
    },
    {
      "Time_Start": 2645.6200000000003,
      "Time_End": 2649.94,
      "Text": " So that's just the academic example of the worst thing they can think of."
    },
    {
      "Time_Start": 2649.94,
      "Time_End": 2654.5000000000005,
      "Text": " But if you wanted code execution, or you're pentesting some LLM that they hooked up to"
    },
    {
      "Time_Start": 2654.5,
      "Time_End": 2658.82,
      "Text": " some function something, it doesn't matter what your input is."
    },
    {
      "Time_Start": 2658.82,
      "Time_End": 2667.66,
      "Text": " It's just that process of, and I guess I'll go back, all the way back."
    },
    {
      "Time_Start": 2667.66,
      "Time_End": 2672.1,
      "Text": " Now that you've heard all of that, here, just a function."
    },
    {
      "Time_Start": 2672.1,
      "Time_End": 2673.26,
      "Text": " What's x?"
    },
    {
      "Time_Start": 2673.26,
      "Time_End": 2674.26,
      "Text": " What do you want to do?"
    },
    {
      "Time_Start": 2674.26,
      "Time_End": 2675.26,
      "Text": " Right?"
    },
    {
      "Time_Start": 2675.26,
      "Time_End": 2676.26,
      "Text": " What's that output?"
    },
    {
      "Time_Start": 2676.26,
      "Time_End": 2678.78,
      "Text": " So I think keep that in mind."
    },
    {
      "Time_Start": 2678.78,
      "Time_End": 2683.74,
      "Text": " And then when you read these academic papers, don't write them off, because it doesn't fit"
    },
    {
      "Time_Start": 2683.98,
      "Time_End": 2686.2200000000003,
      "Text": " your offensive narrative."
    },
    {
      "Time_Start": 2686.2200000000003,
      "Time_End": 2689.6200000000003,
      "Text": " Think of it as just an abstract space that you can work within."
    },
    {
      "Time_Start": 2689.6200000000003,
      "Time_End": 2690.9,
      "Text": " So it doesn't matter what your objective is."
    },
    {
      "Time_Start": 2690.9,
      "Time_End": 2692.5400000000004,
      "Text": " You can optimize for it."
    },
    {
      "Time_Start": 2692.5400000000004,
      "Time_End": 2693.5400000000004,
      "Text": " Okay."
    },
    {
      "Time_Start": 2693.5400000000004,
      "Time_End": 2694.5400000000004,
      "Text": " That's it."
    },
    {
      "Time_Start": 2694.5400000000004,
      "Time_End": 2695.5400000000004,
      "Text": " Fantastic."
    },
    {
      "Time_Start": 2695.5400000000004,
      "Time_End": 2708.5400000000004,
      "Text": " Do we have any questions?"
    },
    {
      "Time_Start": 2708.5400000000004,
      "Time_End": 2709.5400000000004,
      "Text": " This was amazing."
    },
    {
      "Time_Start": 2709.5400000000004,
      "Time_End": 2710.5400000000004,
      "Text": " Thanks, guys."
    },
    {
      "Time_Start": 2710.54,
      "Time_End": 2717.34,
      "Text": " I'm experimenting a lot with LLMs and some of the networks that you showed, but then"
    },
    {
      "Time_Start": 2717.34,
      "Time_End": 2718.54,
      "Text": " without any prior knowledge."
    },
    {
      "Time_Start": 2718.54,
      "Time_End": 2721.7799999999997,
      "Text": " So for me, it's more dabbling than actually understanding what's happening."
    },
    {
      "Time_Start": 2721.7799999999997,
      "Time_End": 2722.7799999999997,
      "Text": " So it's very useful."
    },
    {
      "Time_Start": 2722.7799999999997,
      "Time_End": 2728.38,
      "Text": " And one of the things we were contemplating, and what you triggered with your flows for"
    },
    {
      "Time_Start": 2728.38,
      "Time_End": 2730.82,
      "Text": " the bloodhound one, but it can be anything, right?"
    },
    {
      "Time_Start": 2730.82,
      "Time_End": 2736.54,
      "Text": " Would it make sense to train some neural networks in between to validate the output based on"
    },
    {
      "Time_Start": 2736.54,
      "Time_End": 2741.18,
      "Text": " the prior knowledge that we have so that it can actually re-quantify the next questions"
    },
    {
      "Time_Start": 2741.18,
      "Time_End": 2742.18,
      "Text": " towards the model?"
    },
    {
      "Time_Start": 2742.18,
      "Time_End": 2743.82,
      "Text": " Or is that very inefficient?"
    },
    {
      "Time_Start": 2743.82,
      "Time_End": 2748.58,
      "Text": " Yeah, I was going to say, it could be inefficient."
    },
    {
      "Time_Start": 2748.58,
      "Time_End": 2752.18,
      "Text": " So I think a lot of the big models are really good."
    },
    {
      "Time_Start": 2752.18,
      "Time_End": 2753.3,
      "Text": " Like really, really good."
    },
    {
      "Time_Start": 2753.3,
      "Time_End": 2758.38,
      "Text": " Like I don't know, currently, and we had this discussion last night, it's like, because"
    },
    {
      "Time_Start": 2758.38,
      "Time_End": 2765.34,
      "Text": " we have that, I added that dataset piece in, and the models are so good at the moment."
    },
    {
      "Time_Start": 2765.34,
      "Time_End": 2769.5,
      "Text": " Like I don't know why you, zero shot and like trying to use those big models to validate"
    },
    {
      "Time_Start": 2769.5,
      "Time_End": 2771.54,
      "Text": " is probably your first step."
    },
    {
      "Time_Start": 2771.54,
      "Time_End": 2774.7000000000003,
      "Text": " The next step would be training your own classifier."
    },
    {
      "Time_Start": 2774.7000000000003,
      "Time_End": 2775.7000000000003,
      "Text": " Or a few shot, yeah."
    },
    {
      "Time_Start": 2775.7000000000003,
      "Time_End": 2776.78,
      "Text": " Yeah, that's probably what I meant."
    },
    {
      "Time_Start": 2776.78,
      "Time_End": 2779.86,
      "Text": " So what my primary intention would be, I'm more on the defensive side."
    },
    {
      "Time_Start": 2779.86,
      "Time_End": 2786.06,
      "Text": " So we're trying to build a model to quantify outputs of findings based on the contextual"
    },
    {
      "Time_Start": 2786.06,
      "Time_End": 2788.54,
      "Text": " knowledge of the environment that we're trying to protect, right?"
    },
    {
      "Time_Start": 2788.54,
      "Time_End": 2792.9,
      "Text": " So that knowledge you can't get from an LLM simply because it doesn't know it, it's unique"
    },
    {
      "Time_Start": 2792.9,
      "Time_End": 2793.9,
      "Text": " to that environment."
    },
    {
      "Time_Start": 2794.3,
      "Time_End": 2795.94,
      "Text": " Right, but you can provide it."
    },
    {
      "Time_Start": 2795.94,
      "Time_End": 2796.94,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2796.94,
      "Time_End": 2797.94,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2797.94,
      "Time_End": 2800.42,
      "Text": " So yeah, provide it, and then that's where I think we're all evaluators."
    },
    {
      "Time_Start": 2800.42,
      "Time_End": 2804.38,
      "Text": " So where we have our own metrics for success, you would write your own metrics for success"
    },
    {
      "Time_Start": 2804.38,
      "Time_End": 2806.3,
      "Text": " and then move on."
    },
    {
      "Time_Start": 2806.3,
      "Time_End": 2814.26,
      "Text": " Build your framework around your own metrics, and I think people, like we have these gigantic"
    },
    {
      "Time_Start": 2814.26,
      "Time_End": 2818.34,
      "Text": " models and what people maybe don't want is like a gigantic narrative."
    },
    {
      "Time_Start": 2818.34,
      "Time_End": 2821.42,
      "Text": " What they want is actually for it to say, hey, here's this form, please fill out this"
    },
    {
      "Time_Start": 2821.42,
      "Time_End": 2823.5,
      "Text": " form because I don't want to do it."
    },
    {
      "Time_Start": 2823.5,
      "Time_End": 2828.22,
      "Text": " But that's a long way away from here, generate this story about dragons or whatever."
    },
    {
      "Time_Start": 2828.22,
      "Time_End": 2831.34,
      "Text": " And so there's this weird process where we're like, hey, that's too much, and let's try"
    },
    {
      "Time_Start": 2831.34,
      "Time_End": 2833.1,
      "Text": " and bring it back a little bit."
    },
    {
      "Time_Start": 2833.1,
      "Time_End": 2838.94,
      "Text": " But that process is you imparting your knowledge on and putting constraints around the model"
    },
    {
      "Time_Start": 2838.94,
      "Time_End": 2841.26,
      "Text": " about what you want to see out of it."
    },
    {
      "Time_Start": 2841.26,
      "Time_End": 2842.26,
      "Text": " Yeah."
    },
    {
      "Time_Start": 2842.26,
      "Time_End": 2846.7,
      "Text": " I'd also add, yeah, just in general, like zero-shot prompting, big LLM, few-shot prompting."
    },
    {
      "Time_Start": 2846.7,
      "Time_End": 2851.5,
      "Text": " There's some more recent research on like something shy of fine-tuning where you manipulate"
    },
    {
      "Time_Start": 2851.5,
      "Time_End": 2855.98,
      "Text": " the input weights of the model slightly before you push them through."
    },
    {
      "Time_Start": 2855.98,
      "Time_End": 2859.06,
      "Text": " Then you would go into like LoRa fine-tuning."
    },
    {
      "Time_Start": 2859.06,
      "Time_End": 2863.38,
      "Text": " So yeah, like pick your abstraction layer that you want, but start simple, have measurements"
    },
    {
      "Time_Start": 2863.38,
      "Time_End": 2865.3,
      "Text": " all the way through, and then however deep you want to get."
    },
    {
      "Time_Start": 2865.3,
      "Time_End": 2870.14,
      "Text": " Like if you want to go fine-tune a Mistral model or write an entirely new NLP classifier"
    },
    {
      "Time_Start": 2870.14,
      "Time_End": 2873.14,
      "Text": " using like RNNs, I would say go for it."
    },
    {
      "Time_Start": 2873.14,
      "Time_End": 2874.9,
      "Text": " There's no rules to this game."
    },
    {
      "Time_Start": 2874.9,
      "Time_End": 2875.9,
      "Text": " They're all function approximators."
    },
    {
      "Time_Start": 2875.9,
      "Time_End": 2877.9,
      "Text": " So like it doesn't matter what model you're using."
    },
    {
      "Time_Start": 2877.9,
      "Time_End": 2879.18,
      "Text": " It's all about performance."
    },
    {
      "Time_Start": 2879.62,
      "Time_End": 2884.3399999999997,
      "Text": " Yeah, I think it's worth mentioning that when you, I think when you step into this world,"
    },
    {
      "Time_Start": 2884.3399999999997,
      "Time_End": 2888.54,
      "Text": " like everything's an experiment because of just the stochastic nature of it."
    },
    {
      "Time_Start": 2888.54,
      "Time_End": 2894.06,
      "Text": " And so very rarely will you just be able to pull something off the shelf and it'll work"
    },
    {
      "Time_Start": 2894.06,
      "Time_End": 2895.06,
      "Text": " like consistently."
    },
    {
      "Time_Start": 2895.06,
      "Time_End": 2900.22,
      "Text": " And so, you know, maybe think of it as, you know, not necessarily building a solution,"
    },
    {
      "Time_Start": 2900.22,
      "Time_End": 2902.7799999999997,
      "Text": " but experimenting to find the best solution."
    },
    {
      "Time_Start": 2902.7799999999997,
      "Time_End": 2906.4199999999996,
      "Text": " So I think in a lot of sort of ML production environments, they're not training one model."
    },
    {
      "Time_Start": 2906.42,
      "Time_End": 2909.54,
      "Text": " They're training like 10, 50, 100 models."
    },
    {
      "Time_Start": 2909.54,
      "Time_End": 2914.46,
      "Text": " And then as, you know, the accuracy improves, there's some threshold they hit and they say,"
    },
    {
      "Time_Start": 2914.46,
      "Time_End": 2916.86,
      "Text": " okay, you know, we've hit our training limit, whatever."
    },
    {
      "Time_Start": 2916.86,
      "Time_End": 2921.06,
      "Text": " Now we're going to promote this model to prod because it has the highest accuracy."
    },
    {
      "Time_Start": 2921.06,
      "Time_End": 2929.2200000000003,
      "Text": " But in reality, there's like 49 models behind it that were just not quite as good."
    },
    {
      "Time_Start": 2929.2200000000003,
      "Time_End": 2932.7000000000003,
      "Text": " Would you mind speaking a little bit more about the main sale demo that you had there?"
    },
    {
      "Time_Start": 2932.7000000000003,
      "Time_End": 2939.2200000000003,
      "Text": " Is each one of those nodes a prefect task and what exactly is going on when it branches"
    },
    {
      "Time_Start": 2939.2200000000003,
      "Time_End": 2942.1000000000004,
      "Text": " to multiple different tasks?"
    },
    {
      "Time_Start": 2942.1000000000004,
      "Time_End": 2943.7000000000003,
      "Text": " So that's a map."
    },
    {
      "Time_Start": 2943.7000000000003,
      "Time_End": 2950.7000000000003,
      "Text": " So basically we grab a list of users, we grab their relationships, and then instead of iterating,"
    },
    {
      "Time_Start": 2950.7000000000003,
      "Time_End": 2952.3,
      "Text": " we map them."
    },
    {
      "Time_Start": 2952.3,
      "Time_End": 2955.26,
      "Text": " And so it's just a parallelization technique."
    },
    {
      "Time_Start": 2955.26,
      "Time_End": 2960.26,
      "Text": " And so instead of being like for user, for relationship, do this, which creates a very"
    },
    {
      "Time_Start": 2960.26,
      "Time_End": 2964.5,
      "Text": " long sort of graph, we just map that task."
    },
    {
      "Time_Start": 2964.5,
      "Time_End": 2967.42,
      "Text": " So we can do them all at the same time."
    },
    {
      "Time_Start": 2967.42,
      "Time_End": 2971.1800000000003,
      "Text": " So we do five or however many relationships at the exact same time."
    },
    {
      "Time_Start": 2971.1800000000003,
      "Time_End": 2974.1800000000003,
      "Text": " And then you could just move that map one up to all users."
    },
    {
      "Time_Start": 2974.1800000000003,
      "Time_End": 2977.7400000000002,
      "Text": " And then it would just, you know, you would do all users for any given environment at"
    },
    {
      "Time_Start": 2977.7400000000002,
      "Time_End": 2980.5400000000004,
      "Text": " the same time and go through that triage step."
    },
    {
      "Time_Start": 2980.5400000000004,
      "Time_End": 2984.42,
      "Text": " From an engineering standpoint, Prefect supports sync and async tasks."
    },
    {
      "Time_Start": 2984.42,
      "Time_End": 2987.42,
      "Text": " So, you know, you can effectively take advantage of async."
    },
    {
      "Time_Start": 2987.42,
      "Time_End": 2990.9,
      "Text": " You can also support parallel executors."
    },
    {
      "Time_Start": 2990.9,
      "Time_End": 2995.86,
      "Text": " And yeah, you can do branching inside of flows inside of tasks."
    },
    {
      "Time_Start": 2995.86,
      "Time_End": 3001.48,
      "Text": " It's very dynamic, which is like the reason why we like it as opposed to like more static"
    },
    {
      "Time_Start": 3001.48,
      "Time_End": 3002.48,
      "Text": " data analysis flows."
    },
    {
      "Time_Start": 3002.48,
      "Time_End": 3006.26,
      "Text": " Typically there you would define your graph, execution graph, and then you execute it in"
    },
    {
      "Time_Start": 3006.26,
      "Time_End": 3007.26,
      "Text": " that static form."
    },
    {
      "Time_Start": 3007.26,
      "Time_End": 3009.34,
      "Text": " And it optimizes the graph for you."
    },
    {
      "Time_Start": 3009.34,
      "Time_End": 3013.14,
      "Text": " In a tool like this inside of your code, you can be out of like dynamically adding and"
    },
    {
      "Time_Start": 3013.14,
      "Time_End": 3014.14,
      "Text": " changing steps."
    },
    {
      "Time_Start": 3014.2999999999997,
      "Time_End": 3018.62,
      "Text": " And like if you come across new information, you can like trigger a new subflow or trigger"
    },
    {
      "Time_Start": 3018.62,
      "Time_End": 3020.7,
      "Text": " it with different parameters."
    },
    {
      "Time_Start": 3020.7,
      "Time_End": 3024.2999999999997,
      "Text": " There's also really cool caching layers where like the arguments of the function are all"
    },
    {
      "Time_Start": 3024.2999999999997,
      "Time_End": 3026.14,
      "Text": " used as a cache key."
    },
    {
      "Time_Start": 3026.14,
      "Time_End": 3029.3399999999997,
      "Text": " And then if those arguments all stay the same and you can overload them yourself, then it"
    },
    {
      "Time_Start": 3029.3399999999997,
      "Time_End": 3030.3399999999997,
      "Text": " will pull from the cache again."
    },
    {
      "Time_Start": 3030.3399999999997,
      "Time_End": 3033.3399999999997,
      "Text": " So you effectively get to define when a function is re-executed or not."
    },
    {
      "Time_Start": 3044.14,
      "Time_End": 3045.14,
      "Text": " Yeah."
    },
    {
      "Time_Start": 3045.14,
      "Time_End": 3046.14,
      "Text": " Yeah."
    },
    {
      "Time_Start": 3046.14,
      "Time_End": 3047.14,
      "Text": " Yeah."
    },
    {
      "Time_Start": 3047.14,
      "Time_End": 3047.64,
      "Text": " Yeah."
    }
  ]
}