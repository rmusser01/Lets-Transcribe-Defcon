Will Pearce and Nick Landers, co-founders of Dreadnought, a company specializing in offensive machine learning, present their work on using Large Language Models (LLMs) for offensive security workflows and evaluating their capabilities. They discuss the importance of task-specific prompts and providing context to LLMs, emphasizing the need for tracking and evaluating prompts to improve results. They demonstrate how LLMs can be used with tools like Bloodhound to identify exploitable relationships in Active Directory environments. Additionally, they delve into adversarial machine learning, explaining how to navigate the parameter space of models efficiently, and provide an overview of different attack methods for Natural Language Processing (NLP) models.