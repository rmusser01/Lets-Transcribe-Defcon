**Introduction**
- **Speaker**: Andrea Matwyshyn
- **Topic**: Software liability and security

**Background**
- **White House Cyber Security Strategy**: Released on March 2nd, included a note about the Biden administration's readiness to shift liability for the consequences of poor cybersecurity.
- **Security Liability**: Refers to various legal ways of assigning responsibility for failures, inadequacies, or harms in infosec settings.
- **Tort**: Civil wrongs, private harm, one person sues another. Includes intentional negligence, product liability, and privacy torts.
- **Private Contract Suits**: Arise when one party fails to meet contractual obligations, e.g., not conducting monthly pen testing.
- **Civil and Regulatory Liability**: Results from enforcement by federal or state regulators, may involve fines or promises to take/refrain from certain actions.
- **Criminal Situations**: Can arise from security failures, e.g., EPA's approach to Volkswagen's defeat devices.

**Ecological Model of Security**
- **Uri Bronfenbrenner's Model**: Each layer of security interests (democracy, defense, harmonization, critical infrastructure) influences and is influenced by the others.
- Changes in one layer can have unintended consequences on the others, requiring simultaneous assessment and evolution.

**Historical Perspective**
- **Hoover Dam vs. St. Francis Dam**: The St. Francis Dam failure, due to ignored warnings and lack of oversight, led to a crisis of confidence in engineering and subsequent professionalization of the field.
- **Cuyahoga River vs. Centralia, Pennsylvania**: Nixon's response to the Cuyahoga River fire led to the creation of the EPA and clean water/air legislation. Centralia, a town with uncontrollable underground fires, serves as a warning of potential dark outcomes.
- **Y2K Problem**: A security success story, collaborative efforts between the private and public sectors, assumed liability with a liability shield.

**Simplifying the Conversation**
- Focus on **Context**, **Harm**, and **Intent** (CHI):
  - **Context**: Duty of care, promises made, reasonable expectations, external baselines.
  - **Harm**: Fixability, prevention, loss of life.
  - **Intent**: Important in various legal frameworks and the First Amendment.
- **Threat Modeling**: Existing frameworks often overlook the risk of failures in human internal controls and governance.

**Meta Model for Threat Analysis**
- **Troll**: Technological (regular threat modeling), regularity (user perspective), organizational (incident response, board understanding), and legal consequences (mitigation of harms).
- **Hoover Dam or St. Francis Dam?**: Emphasizes the need for suitability, design, substantiation, security, and sustainability in society and government.

**Hypothetical Scenario**
- **Stinkin' Haul**: A garbage-hauling company with self-driving trash barges and remote override capability.
  - Under-resourced security team, poor patching, and a history of accidents.
  - Attackers exploit a known vulnerability, causing a crash and environmental disaster.
- **Questions**: Who is at fault? What should the response be? (A QR code and URL were provided for audience input.)

**Q&A**
- **Liability in Software Production**: The context of use and knowledge of potential repurposing are important considerations for software producers.
- **Determining Fault**: A finder of fact would consider context, harm, and intent, as well as affirmative steps taken to prevent risks.
- **No Death Principle**: Aiming to not hurt people is an ethical conversation worth having, even if zero deaths is not achievable.
- **Role of Plaintiff's Attorney**: The SEC's new rule on accurate disclosures and the presence of security experts could provide grounds for litigation.
- **Aviation Industry Comparison**: Redundancy structures and the role of the co-pilot are notable, but software defaults and supply chain considerations differ.
- **Professional Certification**: The software engineering profession should decide on the best model for certification and ethical standards.