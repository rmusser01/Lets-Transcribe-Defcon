**Wojciech Lesicki and Andrzej Agria: Attacking and Defending LLMs in Production Environments**

- Large Language Models (LLMs) are being increasingly adopted by businesses, bringing new challenges and vulnerabilities.
- Threat actors are already using LLMs to gain knowledge, automate tasks, and enhance their attacks.
- Vendors are working on safety evaluations and blocking malicious use, but it's a complex and evolving landscape.
- The talk covers definitions, systems using LLMs in production, attack methods, and potential defenses.
- Jailbreak attacks, remote code execution, and sleeper agent models are among the threats discussed.
- Mitigation strategies include guardrails, additional LLMs for input/output, and vendor solutions like Azure AI Prompt Shield.
- Understanding LLMs' inner workings is crucial but challenging, and new breakthroughs offer hope for better interpretation.
- Takeaways include the increasing popularity of jailbreaking, the need for data classification, and the importance of security foundations.