{
  "webpage_url": "https://www.youtube.com/watch?v=PAxYI99A0mg",
  "title": "16. BYOT: Build Your Own Tools for Fun and Profit by Cas van Cooten",
  "description": "Threat intelligence shows that malicious actors are diversifying their malware codebase. As such, the red team also needs to step up their malware development game. What's that? You know nothing about malware development or obscure programming languages? Great, then this talk is aimed at you!\n\nHow do I stay undetected during red team operations?\nWhy build your own tools when there are so many open-source alternatives?\nWhat programming language do the cool kids use nowadays?\n\nIn this talk, Cas will address these questions and more based on a case study of his offensive security tools written in the Nim programming language. The design decisions behind 'NimPackt' and 'NimPlant' will be addressed and used as a guide to touch upon several themes that are very relevant in today's offensive security space: malware development, operational security, and defense evasion\n\nThe talk covers several topics related to the development of custom malware:\n\nWhy malware development is an essential skill for any red team operator;\nHow custom tooling and obscure programming languages help evade defenses;\nWhat (not) to do when writing your own custom tooling;\nHow to defend against malware that is not publicly known.\nWhile both the offensive side and defensive implications of these topics will be discussed, the talk is primarily aimed towards offensive security professionals. The talk is suitable for beginners with a foundational technical understanding.",
  "channel_url": "https://www.youtube.com/channel/UC8wesSvHdlNXVZgSy_UU_Ug",
  "duration": 2713,
  "channel": "x33fcon",
  "uploader": "x33fcon",
  "upload_date": "20220829"
}

This text was transcribed using whisper model: large-v2

 So, good afternoon, everyone.  It's Friday afternoon, second to last talk of CFCon.  I hope you all have some energy left to sit through these last two talks.  I'll try not to ramble on too long.  So we've had a lot of excellent talks today, mostly quite technical.  So for this talk, I would like to kind of take a step back and go a bit higher level  and talk about the necessity, really, of an offensive development capability for red teams.  Before I go into that, I would like to introduce myself and also kind of explain why you have  to listen to me ramble on this topic for 45 minutes.  So my name is Cas van Kooten.  I'm a red teamer at a large financial institution in the Netherlands.  That also explains my accent.  So sorry about that.  The Dutch-English accent is really horrible.  I actually started out as a security consultant.  So I studied information science, which is not at all very technical.  It's more business-oriented.  So I started also as a cybersecurity consultant, talking about privileged access management  implementations and security policies, rather than actually doing the hands-on work.  But a couple of years into my career, I realized that hacking was way more fun.  So I kind of did a lot of courses, did the OECP, OECP, a couple of others, and rolled  into the dark side of security, being red teaming.  So nowadays I am the bad guy, and I focus on researching and thinking like the bad guys  and bringing these attacks into practice.  And when I started doing that, I also got an interest in the field of malware and specifically  malware development.  But because I am not that technical still, I really avoided learning C. So I picked up  the NIM programming language, which is like a higher-level version of C and C++.  We will talk about it a couple of times during this talk.  I will also have a DEF CON talk on this topic at Adversary Village.  So if you're there, come find me.  And I built a couple of tools that I published in NIM as well.  So we will discuss two of them today, NIMPact and NIMPlant.  But I also released a couple of other random tools, like CloudLabs AD, which is an online  lab environment like the ones that Tim just mentioned, and also a bug bounty scanner,  which I wrote back in the day.  If you want to follow me, you can find me on various social media.  I mostly focus on posting on Twitter.  Not too good at managing the other feeds.  And I like to post about half memes there and half technical content.  So let's also take a minute to discuss what I am not.  I already mentioned that I'm not too technical.  I am also not a developer.  Which may sound weird, because I'm giving a talk, 45 minutes, about offensive development,  right?  But I'm actually convinced that to get into this field, you do not need to be a developer,  right?  Or you do not need to be a software engineer.  So I'm mostly self-taught.  So if any of you are actual developers and you look through my code, probably you will  have several cringe moments, because I know nothing about actually properly structuring  your code.  I know very little about design patterns, stuff like this.  But I make my code work, right?  And if it works, it hopefully ain't too stupid.  So I would also like to give this to you.  If you want to get into the field of malware development, don't be stopped by the fact  that you may not know a lot about development before you start.  So before we get into what offensive development is, let's talk a little bit about what redteaming  is and why the redteamers love tools so much.  Because we all know the redteamers love tools.  They use them all the time.  Why is that?  That stems actually from a couple of challenges that we have as redteamers.  Of course, as redteamers, we are very proud of our field of work.  We like to brag about the cool hacks that we do and how lead we are.  But redteaming has a couple of challenges.  So first of all, redteaming is quite hard.  There is a lot to learn, especially when you're starting out as a redteamer.  But even for experienced redteamers, there is a high pace of information that you need  to keep up with in order to stay ahead of the blue teams.  You need to know a lot of technical information.  And you need to know the balance between the commands you're running and the risk of detection,  for example.  So just as a thought experiment, by show of hands, how many of you are in offensive security?  Or redteaming?  About half.  Out of those people that just raised their hand, how many of you understand Kerberos?  You guys are lying.  No one understands Kerberos and I am convinced of it.  Which is kind of a nice case in point, right?  Of course I'm joking there.  But Kerberos is one of the things, like the protocols, that is very complex.  And especially if you're just starting out in redteaming and someone starts talking to  you about TGTs, service tickets, delegation, all this type of stuff.  That's a lot of information coming at you.  And you need to keep up with this stuff.  So that's kind of the first challenge of redteaming.  Another challenge is that during redteam ops, there is a lot of risk.  And I mean risk in two senses of the word.  So in the first sense, as redteamers, we are almost exclusively testing in production.  So we are touching client systems or touching systems within our internal company that are  probably business critical, right?  And they are production systems.  So you all know the phrase, don't test in production.  We are doing the exact opposite.  So every action we take has an availability risk.  So if we mess up, if we accidentally run the shutdown command, or do something that crashes  an essential process on the system, we are actually affecting production services.  Which can be very bad news, right?  Especially for companies that are operations focused.  The other sense of the word risky is the OPSEC risk, the operational security risk.  So we are trying to stay undetected as redteamers.  And every action that we run kind of has an implication for the operational security.  In other words, for every action or command that we run, we have a varying level of risk  to be detected.  And as a redteamer, you need to kind of know at every step you're taking, for both these  types of risks, what the implications are.  That's also hard to pick up if you're just starting out.  Further, we don't like to admit it, but parts of our job really are repetitive.  For example, if we are scanning the external perimeter of a company, there are tens of  thousands of web-facing machines, and we want to know what is running on all these machines.  We are of course not going to do that by hand, right?  So we are trying to automate this type of repetitive task.  So why am I telling you all this?  I'm telling you all this because basically, tools can help at every step of this process.  So the hard part of the job, we can learn from tools, right?  If you're starting out and you're trying to understand, for example, Kerberos, what you  can do is you can go to GitHub and analyze some of the tools that are there that exploit  attacks against Kerberos or interact with it in some other way.  You can kind of make a collection of these tools that you find interesting, and you can  analyze them and learn from it.  Tools can also help with the risky part of our job.  Most notably, one of the big advantages of using tools is that we can verify what they  are doing.  So if we run either an availability risk or an operational security risk, we can kind  of make that into a tool.  We can verify with other Red Teamers maybe what do you think the risk of running this  tool is, and we can then run it.  If something goes wrong, we can also analyze the tool and kind of see at what step the  mistake has been made.  So it's also traceable.  And of course, the repetitive task I already mentioned, we can automate.  So if there's 10,000 machines we need to scan, we can just run a scanner, and we can also  run tools to automatically analyze the output.  So in short, Red Teamers love tools because it makes our job a lot easier, and it also  makes a good Red Teamer to know your tools, know to find the right tools, and know how  to use them.  Then the next question kind of becomes, where do we get these tools?  You all know this struggle, especially if you're in offensive security.  If you go to GitHub, you download, let's say, Rubius to do something on your target system,  and you load it on the target system, you will get this nice Defender pop-up that says,  malware has been prevented.  It is no longer an option for us attackers to just use tools that are off-the-shelf.  Especially if they're malicious, sometimes you can get away with them if they have some  kind of legitimate use case, right?  We just talked about Lolbus, for example.  There are some edge cases where tools off-the-shelf, they do work, but that's a matter of tradecraft.  In general, the blue team is advancing so quickly, luckily, because that's also part  of our job.  It's advancing so quickly that all these tools that we know and love don't cut it anymore.  Basically just grabbing these tools, copy-pasting them on our target environment is no longer  an option.  Then, what is the option that we have to get these tools?  There are a couple.  First of all, we can take the effort to actually build the tool from scratch.  We can develop it ourselves.  That already implies quite a big investment in terms of time.  We all know time is money, so for probably your employer, that's a big money investment.  But it comes at the advantage of having full control over techniques and the procedures  that you can apply on a target system.  There's a trade-off between effort and reward there.  If you do not want to make that investment, what we can do is we can take the open-source  tools, maybe some closed-source tools that you have access to, and we can modify them  instead.  You take an existing code base and you modify it to fill your needs.  Likely that's going to be evading defenses, right?  Because we just mentioned that if you deploy a known tool on a target, it will get detected.  We can tweak it so that it's not detected anymore.  A bit less of a time investment there, so the investment also in terms of money is lower,  but you also hand in some of the advantages that actual development gives you.  Finally, we can decide that we either are not in the mood for development or we just  don't have the capability, and we can just throw a bag of money at the problem to make  it go away, i.e. buying tools from other parties.  There's a couple of colleagues in this corner here that basically provide the service.  For example, Outflank has the OST proposition where you can basically buy their offensive  tools as a service, but a very common bold capability for red teams is, of course, the  command and control solution.  Also shout out to Nighthawk in the same corner there.  You can buy these tools to not make the effort yourself, and the advantage of that is you  are basically outsourcing the issue of continuously modifying this tool to stay on top of signatures  and the latest evasions.  There were a lot of talks on, for example, sleep time encryption or call stack spoofing.  You don't have to get what is actually happening.  You just need to know how to use the tool in a proper way.  These are kind of the options that you have to use tools as a red teamer in a modern environment.  I would like to zoom in a little bit on the actual topic of development, because this  talk is titled Build Your Own Tools, so we're going to discuss a little bit on what the  advantage of that is.  We're zooming in on the first block here.  I already mentioned that development is the biggest investment of them all, but of course  there are a couple of advantages there that you can reap the benefits of.  First of all, developing a tool gives you full control over whatever you are doing.  That makes sense, right?  You develop it so you can decide from the ground up which design decisions you take  to fulfill your goals.  Of course, in the context of red teaming and especially adversary emulation, this means  that you can exactly decide which TTPs or which IOCs you apply.  This gives you also full flexibility to, for example, emulate known threat actors, if that  is your goal, or to stay away from known bad behaviors to evade defenses, for example.  It gives you full control.  Secondly, and I already mentioned that actually, it helps with defensivization.  Defenders are doing a great job.  Shout out to all the blue teamers in this room.  Of course, our job as a red teamer is to help that.  The way we do that is to challenge them, right?  It's to stay undetected in ways that also teach the defenders new techniques.  If you develop your own tools, because of this flexibility that you get, that means  that you can stay away from all the known bad that is used by defenders to kind of identify  that you're doing something malicious.  It helps with defensivization.  It's a great learning experience.  I already mentioned I'm basically self-taught in programming.  That's all because I kind of like to build this malware myself.  At first, I had no idea what I'm doing.  I'm just looking at GitHub scripts, kind of throwing it all together to come up with something.  I noticed, hey, that works against defenses, right?  In the meantime, you're also discovering a programming language.  In my case, I learned Nim by just starting to program in Nim.  You're learning about all these topics that we mentioned, for example, call stack spoofing  or whatever technical topic you want to learn.  If you implement it, you have a really intimate experience with understanding how it works  and how to execute it in practice.  There's no better way to learn these techniques than to actually implement them in a tool.  And finally, it's fun.  Yeah, I can be long or short about that one, but if you like programming, I know a lot  of red teamers whose hobby it actually is to program stuff in their free time.  If you like doing this stuff, that means that it's also fun to write malware, right?  Our job is basically a giant game of cat and mouse.  The same goes for malware development.  It's fun to see your malware evade defenses, right?  It's fun to try to identify what allows defenders to detect you and then try to get around that.  It's overall a large investment, but it has many benefits and it's fun as well.  We're talking about offensive development and another term that you hear often is malware  development.  In my eyes, these are not the same, so I have tried to make a bit of a definition on the  difference between the two.  A small disclaimer with this slide is that I basically pulled it out of somewhere.  The sun doesn't shine.  I made up this definition myself, so this is definitely an arguable definition, but  I would still like to show it to distinguish between the two.  I mentioned offensive development, which in my eyes is the superset of all development  that is used to support any offensive operations.  A good example might be network scanners, right?  I wouldn't consider them malware per se, but they can be used to support red teaming engagements  or even pen tests if you want to.  Building a network scanner is not malware development, but it is offensive development.  Within that field of offensive development, we also have the field of malware development.  I kind of gave it the arbitrary definition of any malicious tools or tools with malicious  intent that are intended to be run on a target system.  Of course, there are a lot of varieties of this still, but it kind of narrows down the  difference.  If you look at, for example, a C2 framework, we have the C2 server, which is running on  your infrastructure.  It's not touching the target per se.  I wouldn't consider writing the C2 server actually malware development.  However, we have the C2 implant as well.  The C2 implant, of course, is designed to run on the target system.  Notably, it's designed to run covertly, so without detection.  I would then say that writing the actual implant of a C2 is malware development.  The reason I'm making this distinction is that if we look at malware development specifically,  we kind of have a whole different implication of the way that we need to think about our  code.  We are trying to be evasive, so everything that we do in malware development is centered  around this kind of offset cost that I also mentioned before.  We are trying probably to minimize the amount of code, minimize our footprint on the target.  In an operational sense, we are trying to stay off disk and in memory.  All these kind of implications are very important for malware development.  With this definition, of course, there are some kind of edge cases slash exceptions.  For example, if you look at Mimikatz, I would consider the memory dumping part, which runs  on the target, to dump LSAS, for example.  I would consider the malware part, but if you take it offline and analyze it on your  Akali machine, for example, then you're looking at offensive development.  There's a couple of other examples here.  Again, slightly arbitrary definition, so feel free to argue with me on that topic, but that's  just to clarify the distinction.  Coming in on malware development a little bit, I often get the question when I tell  people that I teach about malware, especially from people outside of the industry, I get  the question, why?  Why are you teaching people something that is, by definition, malicious?  That's a good question, right?  Everyone kind of has an opinion on this.  Some would argue that you're giving the bad guys the knowledge that they need to do bad things.  I would argue that, of course, to make this transparent is good for the entire industry.  I hope you all, being industry professionals, you kind of agree with me there.  Again, we can have a debate about that over a beer later this afternoon.  But yeah, I would argue that having this knowledge freely available, especially if it's already  out there being abused by bad guys, is good for the industry, and that everyone in this  room kind of picking up this field of interest and applying it for a good purpose, i.e. growing  our defenses, maturing our defenses.  That's a good thing for us as industry.  That's also why I'm very open about the fact that I write malware.  I also open source most of the malware that I write, unless I use it in active operations.  I would encourage you all to do the same.  If you get into malware development, there's a very important decision to make, and that  is what programming language to use.  For people that already do development, this may be an easy question to answer.  But underwater, there's a lot of considerations that you need to take to decide which programming  language that you use, because essentially, as a malware developer, you can use any language  that you want, but they all have their benefits and they all have their drawbacks, right?  So a couple of considerations when choosing a programming language are shown here.  One of the most important ones for malware developers is how high level is the programming  language that you use.  For example, I know some seasoned malware developers in that corner, they prefer going  as low as possible, meaning in this case, using a language like C or C++ that is a pain  in the ass to learn, but it gives you the most flexibility that you can get, because  there's very little abstraction in the language.  There's also very little guidance in the language, but it just gives you the raw tools that you  need to interact with the operating system, for example.  That's what C or C++ is.  On the other end of the spectrum, you have the high level languages.  These are the languages that add layers of abstraction to make your life easier, so they're  easier to understand, they're easier to read, they're easier to write, but these levels  of abstraction also make it so that you have less control over what your program is actually  doing.  A good example of that would be Python, where almost the syntax of Python is similar to  English language, right?  Even if you don't know Python at all, there are chances that you can read a Python program,  kind of understand the logic and see what it's doing.  But in order to implement that, it's sacrificing a lot of the control that you have in lower  level languages, such as C or C++.  Another important consideration is whether a language is interpreted or compiled.  I think most of the people in this room would be familiar with the difference.  In short, interpreted means that you run a binary like Python.exe, or you install a binary  like Python.exe on your system, and when you run a program, basically this interpreter  will read your code line by line and kind of interpret it, so see what does this line  mean and execute it.  On the other end of the spectrum, we have compiled languages.  This means that if you wrote your code and you're happy with it, you will run a compiler,  which kind of, at that moment, looks at your code, looks at the entire snippet, or like  the entire source code, and decides, okay, how can I translate this into machine code  while optimizing it?  So there's one moment where you press compile, and at that moment, your source code will  be translated into machine code.  That has the advantage that once you generated your binary, so on Windows, the famous example  would be the .exe executable, once you press compile and you get the binary, you can run  it more or less everywhere.  In malware development, we often look at compiled languages because of this portability, right?  If we want to run Python code on a client, that means we also have to ship the Python  interpreter.  If that's not expected in a client environment, that may not suit our goals, right?  Because just dropping Python.exe on an accountant's computer could be very, very suspicious.  We can also, of course, make advantage of that.  If we hit a developer machine which already has Python installed, suddenly that suspicion  is gone, so we can make use of that.  But that's, I would say, in malware development, more of the exception.  So we look mainly at compiled languages.  Then we have two more points.  So we have a developer experience, which is kind of my catch-all to describe how happy  you are or how sad you are while writing a language.  This includes that high or low level, as I just mentioned, but it also includes how good  the documentation of a language is and, very importantly, how big the community is.  For Python, again, a good example of a great developer experience where if you just type  a very niche question into Google, you will probably get an answer to that very niche  question in the form of someone on Stack Overflow that did it in 2011 and just pasted the code  snippet that you can reuse.  This makes a very good developer experience where you can just look at this code and learn  from it and implement it yourself.  The final point is prevalence, which kind of describes how often or how much is a language  actually used.  Especially the prevalence in malware development is interesting because if a language is used  a lot for malware, that means that defenders will also kind of move their spotlights to  look at that language, right?  So C and C++ is, I think, one of the most prominent languages for malware, which means  that defenders are also kind of scrutinizing binaries generated in these languages to try  and identify what makes this malicious.  This point is also the point that kind of causes the interestingness of newer languages  like Go, Nim, or Rust, because if a new language is released, basically no one gets it right,  including defenders.  So if a binary has a certain format that is not very well-known yet, then you can make  or kind of abuse that to slip through the cracks of defenders.  That's exactly what threat actors are doing currently.  So if you look at the kind of trend lines of which languages are used for malware, of  course I mentioned C, C++ is kind of the all-time high and still remaining that way.  But you also see that threat actors are moving towards the younger and the newer languages,  because of these evasion benefits that it gives.  So the landscape, I would say, looks a little bit like this currently.  I'm sure I'm offending a couple of people that look at other languages for malware development  right now, and this is by far not an exclusive list, of course, but I think that especially  the kind of right part of this slide are the languages that we see the most for malware  development now.  And especially a shout-out, of course, to the younger languages, Rust, Nim, and Go,  which are being abused by these threat actors in an increasing fashion.  Now we discussed the reason why people are switching to these newer and younger languages,  which is defense evasion, and I kind of want to summarize briefly what defense evasion  is.  We've had two days of talks on novel techniques which also help with evasion, but just kind  of let's take a helicopter view and look at what exactly are we trying to achieve with  evasion.  Why are we even developing our own malware in the first place?  In short, it's to avoid these areas of defenses, right?  Especially in malware development, what we are dealing with prominently is antivirus  and EDR.  So antivirus, of course, you all have it installed on your own computer.  Typically on Windows, it would be Windows Defender AV.  It's often kind of ridiculed even in the malware developer field because it's fairly  easy to bypass because antivirus kind of makes a habit of trying to fingerprint known bad.  And also, very often, antivirus is static, right?  So it's looking at artifacts on disk, for example.  Maybe it's peeking into memory here and there to try to determine which processes show known  bad indicators.  But because it's fairly static, it's also easy to modify your code in a way that bypasses  these kind of static indicators.  The more challenging counterpart of AV is EDR.  Of course, EDR is much broader than just the part that looks at malware on a host machine.  In a very basic sense, EDR looks at the dynamics of a program that is running.  It looks into the memory.  And even if it's not known bad, but it exhibits indicators that might indicate bad behavior,  it either kills the process or it goes to the SOC and alerts.  So as malware developers, we are trying to kind of slip through these cracks, right?  We are trying to make our binary in a way that it at least gets past these two.  Of course, there are a lot more defenses.  Again, shout out to the blue team, the people actually sitting in the SOC to look at all  the alerts that are coming in.  Once these people actually get to see an alert which shouts out your malware, basically you  are screwed, right?  You are burning your first line of access and hopefully you have another line there.  So again, what we're trying to do is staying away from the blue team.  How do we actually do that?  There's a couple of decisions that we can take there.  At a very high level, we have these decisions to make.  So a very obvious first decision on evading defenses is avoiding defenses.  Sounds like kicking in an open door and it kind of is.  But if we operate in an environment that has, for example, EDR installed on the endpoint  and we can avoid the endpoints altogether, so for example, instead of running our malware  or a malware implant on a system with EDR installed, we can proxy into the network and  run it over the network, then we avoid the defense altogether, right?  This is great and this is probably one of the most efficient ways to bypass defenses.  But unfortunately, it's not always possible because, of course, the blue team is trying  to continuously increase their coverage on both a host level and a network level.  So hopefully in your organization, the places where you can actually do this are fairly  limited.  We can also blend in.  Blending in I would define as either slipping through the cracks, so making your malware  behave in a way that is believable enough to be let through by AV and EDR, or making  clever use of the blind spots of defensive products.  That kind of ties into the previous point as well.  But another point could be that on the endpoint, even if there is AV installed but not EDR,  that means that we can kind of dive into the memory level to go around the defenses that  are installed, right?  To blend in in a way that even if some telemetry is gathered from our malware, it's not alerted  on at the very least as malicious.  Finally, we can also sabotage the defenses that are there.  A common example of that in the case of EDR is, for example, to unhook the APIs that we  use.  So hooking is, of course, a defensive mechanism applied by EDRs.  If we unhook it, we basically kick the EDR so that it gathers a little bit less telemetry,  and hopefully then we can use that as a crack to slip through.  Again, this can be effective depending on the defensive products that you're up against,  but not always possible.  So in general, defensive evasion is a combination of these three, depending on the target environment  that you're up against.  I mentioned I had two case studies of tools that I built.  The first is Nimplant, which is a basic first-stage command and control implant built in Nim.  It has an accompanying C2 server built in Python, because I'm, as I mentioned, not too  technical, so I'm still most comfortable with Python.  Some people would probably shame me for that, but I think it's an interesting case to discuss  because it is kind of a prime example of what slipping through the cracks looks like.  Because I'm very confident in saying that the reason that Nimplant bypasses defenses  at all is that it's not public.  It's a tool that I built, right?  As I mentioned at the start, building this tool kind of gave me the full flexibility  to implement, for example, the way it does C2 communications in the way that I wanted  it to, and defenders haven't seen this.  Even though this tool isn't that advanced, it still evades defenses because the behavior  is not known bad, right?  It makes use of this slipping through the cracks mechanism to bypass AV, even bypass  EDR, and it works for that reason really well in operations, even in mature environments  like the bank that I work at.  One of the lessons learned, if I look back at designing Nimplant, is that it is worth  the effort to actually think about what you want to achieve ahead of time.  I started this project really eagerly, and I basically just started rattling on my keyboard  to build some of the cool functionality that I wanted to implement.  If you actually want to use these tools, I would not recommend that because I had to  go back a couple of times to actually shave off some of the bullshit that I had written  in this code, and optimize it, and also make it more evasive because some of the things  I did at the start were just really dumb design decisions.  If you want to pick up a project like this, take a day or something to think about the  design, think about the functionality that you want to implement, and think about how  you are going to make it evasive.  Quick example of what that looks like, here is the front end of Nimplant, which I am quite  proud of because I actually rewrote it myself, so that was a nice foray in the field of front  end development.  Here you can actually see an example of why I don't like the term fully undetected, because  even though Nimplant, and in this case the self-deleting dropper that Nimplant includes,  is not detected by AV or EDR, or in this case Defender for Endpoint, I should specify.  We can see that if we look into the telemetry that's actually generated, it's still spotted,  right?  So in this case, the execution of an unsigned executable, of course, is suspicious, and  you can see that the attributes of the PE themselves are also marked as suspicious.  But combined, this was not enough for Defender for Endpoint to say, okay, I'm going to raise  an alert.  So again, you don't have to be fully undetected all the time, as long as you slip through  the cracks and keep these indicators as low and slow as possible, so that that alert is  not generated and it does not reach the blue team.  A kind of more interesting example in the sense of evasion is Nimpact.  Nimpact is a packer that I wrote, actually wrote it twice, open sourced the previous  version and at the same time started a full rewrite, because again, I just started coding  and after a while realized that the initial code that it has wasn't cutting it anymore.  But what Nimpact does is it takes code that is typically known bad, so let's say for example  a Cobalt Strike beacon shellcode, if you drop that unencrypted on a target system, of course  it will be flagged and it will be removed.  So what Nimpact tries to do is to take this known bad, ingest it and wrap it in a way  that it can be executed on a target system.  I should note there that Nimpact is only used in cases where you actually want to drop on  disk of the target system, so it generates for example a DLL or something that you can  use, so it's not always ideal.  But it is very handy if you want to run something on a target system and you don't want to pack  it manually every single time.  Again, the lesson learned, as I mentioned, I started coding like a monkey on my keyboard  and it worked, kind of, for the first couple of months.  But I would encourage you, if you want to pick something up like this, to first of all  keep it simple, so use the KISS principle there, and also look at the modularity of  your code, because especially in a tool like this, you may want to replace the functionality  that it has every so often, right?  You want to implement the latest and greatest loading methods and fancy functionality like  call stack spoofing or sleep encryption, but if you write like a giant monolith of a script,  that's going to be hard to implement, and it's going to keep getting worse.  So for a project like this, think about modularity and how you're going to interchange the various  parts of your code once you start building upon it.  Again, this is what it looks like, an impact of course is a bit harder to slip through  the cracks with, because if it is spotted, the behavior that it exhibits is very suspicious,  so think for example process injection could be, if it is spotted by an EDR, very quickly  marked as malicious with fairly high certainty, and you can see here that that's actually  exactly what happened, but even in this scenario, which I wouldn't really use in production  because I did this as a demo to show the difference between alerting and telemetry, even if you  look at these events that are generated by Defender for Endpoint EDR, if you look at  it and you know it's malware, that's like, why did it not alert, and I'm actually still  thinking that looking at this, but no alert was raised, and even for this process injection  that it exhibited, it slipped through the cracks again.  So a couple of final words for the people that actually want to get started in the malware  development field, I think I already touched upon some of the points that are on the slides  here, but just do it, just get started.  If you write ugly code, some people may ridicule you for it, if you use Nim or Python, some  people may ridicule you for it, but it's better to have ugly code that works than not have  any code at all, right, or get detected using only public tools.  As I mentioned, a lot of people are not shy at all about the fact that they write malware,  so there's a great community, I'm very active on Twitter, for example, but you also have  the Bloodhound Slack or even communities for specific languages, and make use of that.  So if you get stuck, just ask people that are in this space on what you could try to  get out of that hole you are stuck in.  And of course there are a lot of excellent resources on GitHub and GitLab and stuff like  this, one note on that is never blindly copy and paste, because first of all, as we mentioned  at the start, public code is almost always fingerprinted if it's malware, so you will  just get those fingerprints into your own code, and additionally you won't learn from  it, right?  Instead of copy-pasting, try reading the code, understanding what it does, and then implementing  that yourself.  A couple of resources, a side note, I will publish these slides on my GitHub as well  with clickable links, so you don't have to remember this, but one of the things I have  to give a shout-out to myself, because I just recently published a workshop, MalDev4Dummies,  which kind of discusses the early steps into malware development, specifically focusing  on writing your first shellcode loader.  It was designed for C-sharp and NIM, but actually this week someone submitted a pull request  for Golang as well, so if you're interested in those languages, check that out, but the  workshop is designed to be generic, so you can just use any programming language that  you're familiar with.  I also listed a couple of other resources with the respective languages, a shout-out  to Sector 7 for the excellent malware development courses, I listed essentials here, but there  are a couple of chapters that kind of take you from zero to hero, really, in the malware  development space, and other than that, there are a lot of resources, as I mentioned, on  GitHub, depending on the language that you want to use.  You could even go to Google and just randomly search for shellcode loader plus programming  language name and find interesting examples.  So summarizing this into defensive implications, small side note, I am a red teamer, so probably  this is kicking in a lot of open doors for you, but I think it's nicely summarized in  the talk that Chris Peacock had yesterday in the Department of Pain, right?  So looking at hashes is near worthless, because as we saw, it's very easy to make malware  that's different every time.  So try to focus on the DTPs instead of the specific tools to detect this type of stuff.  And very importantly, attackers also follow trends.  So if someone goes on Twitter and says, hey, Sliver is the new cool, lots of people will  try Sliver, right?  And the same goes for malware development.  Someone goes and says, hey, Nim is really cool for malware development, lots of people  will try that.  So try to stay on top of this in the form of that intelligence or other feeds to understand  what attackers are doing and focus your detections on that, because that may be the next big  thing that is abused.  Finally, some takeaways.  I think it can all be summarized in one takeaway, really, which is if you think this is interesting,  just get started.  Malware development and offensive development in general is no longer an optional capability  for red teams.  Defenses are maturing and so should your development capability.  That doesn't mean that you have to do everything yourself.  Of course, you can develop, modify, or just buy your offensive capability, but it's definitely  no longer optional.  So just look into this field, motivate your colleagues to start working on this stuff  and improve your next red team operation.  That's it from my side.  Thank you very much.  Bye.  Bye.  Bye.